{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c0be77-da31-4ba5-ad6a-292eb99a4d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution After Normalization:\n",
      "Class\n",
      "Non-abusive    1366\n",
      "Abusive        1366\n",
      "Name: count, dtype: int64\n",
      "Cleaned dataset saved to: C:\\Users\\VARUN BALAJI\\cleaned_AWT_train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data = pd.read_csv(\"filtered_file.csv\")\n",
    "data['Class'] = data['Class'].str.strip().str.capitalize()\n",
    "data['Class'] = data['Class'].replace('Abusive', 'Abusive')\n",
    "print(\"Class Distribution After Normalization:\")\n",
    "print(data['Class'].value_counts())\n",
    "\n",
    "downloads_folder = os.path.expanduser('~')\n",
    "cleaned_file_path = os.path.join(downloads_folder, 'cleaned_AWT_train.csv')\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to: {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9086f3d6-e095-4485-ade0-c373fb172f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>கார்த்தி நா பாத்த. அவன .முகத்த மட்டும் பாத்துர:</td>\n",
       "      <td>Non-abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Appo sri vanth உங்களுக்கு ஹெல்ப் பண்ணது எல்லாம...</td>\n",
       "      <td>Non-abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>இது ஒரு லூசு அது ஒரு லூசு இந்த ரெண்டு லூசு உங்...</td>\n",
       "      <td>Abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>என்ன மாறி யாரேல்லாம் இங்க கமெண்ட் படிக்க வந்தவ...</td>\n",
       "      <td>Non-abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>உங்களுக்கு எ‌ல்லா‌ம் சிலை தான் வைக்கணும்.........</td>\n",
       "      <td>Non-abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ஐயோ கன்னித்தீவு மாதிரி இருக்குடா சாமி.....திண்...</td>\n",
       "      <td>Non-abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>கோத்தவா இது ஒரு பிரச்சனைனு இதை ஒரு நிகழ்ச்சியா...</td>\n",
       "      <td>Non-abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>இந்த எபிசோட். பார்த்தால் பைத்தியம் பிடித்து வி...</td>\n",
       "      <td>Non-abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>உண்மை தெரிச்சு பேயிட இவலவு நாள் வரதவன் இனிய வர...</td>\n",
       "      <td>Abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>தறுதலைக்கு தமிழ்உச்சரிப்பே சரியா வரல இவளையும் ...</td>\n",
       "      <td>Abusive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text        Class\n",
       "0    கார்த்தி நா பாத்த. அவன .முகத்த மட்டும் பாத்துர:  Non-abusive\n",
       "1  Appo sri vanth உங்களுக்கு ஹெல்ப் பண்ணது எல்லாம...  Non-abusive\n",
       "2  இது ஒரு லூசு அது ஒரு லூசு இந்த ரெண்டு லூசு உங்...      Abusive\n",
       "3  என்ன மாறி யாரேல்லாம் இங்க கமெண்ட் படிக்க வந்தவ...  Non-abusive\n",
       "4  உங்களுக்கு எ‌ல்லா‌ம் சிலை தான் வைக்கணும்.........  Non-abusive\n",
       "5  ஐயோ கன்னித்தீவு மாதிரி இருக்குடா சாமி.....திண்...  Non-abusive\n",
       "6  கோத்தவா இது ஒரு பிரச்சனைனு இதை ஒரு நிகழ்ச்சியா...  Non-abusive\n",
       "7  இந்த எபிசோட். பார்த்தால் பைத்தியம் பிடித்து வி...  Non-abusive\n",
       "8  உண்மை தெரிச்சு பேயிட இவலவு நாள் வரதவன் இனிய வர...      Abusive\n",
       "9  தறுதலைக்கு தமிழ்உச்சரிப்பே சரியா வரல இவளையும் ...      Abusive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc8fafb5-a823-4925-abb5-5e1b6823f25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Before Handling:\n",
      "Text     0\n",
      "Class    0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values After Handling:\n",
      "Text     0\n",
      "Class    0\n",
      "dtype: int64\n",
      "\n",
      "Preprocessed dataset saved to: C:\\Users\\revan\\preprocessed_AWT_train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"cleaned_AWT_train.csv\")\n",
    "print(\"Missing Values Before Handling:\")\n",
    "print(data.isnull().sum())\n",
    "data.fillna({'Text': ''}, inplace=True)\n",
    "data['Text'] = data['Text'].str.lower()\n",
    "print(\"\\nMissing Values After Handling:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "import os\n",
    "downloads_folder = os.path.expanduser('~')\n",
    "preprocessed_file_path = os.path.join(downloads_folder, 'preprocessed_AWT_train.csv')\n",
    "data.to_csv(preprocessed_file_path, index=False)\n",
    "\n",
    "print(f\"\\nPreprocessed dataset saved to: {preprocessed_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b0d057-6606-4a8f-95b5-fbc01c5de0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text        Class\n",
      "0       கார்த்தி நா பாத்த அவன முகத்த மட்டும் பாத்துர  Non-abusive\n",
      "1  appo sri vanth உங்களுக்கு ஹெல்ப் பண்ணது எல்லாம...  Non-abusive\n",
      "2  இது ஒரு லூசு அது ஒரு லூசு இந்த ரெண்டு லூசு உங்...      Abusive\n",
      "3  என்ன மாறி யாரேல்லாம் இங்க கமெண்ட் படிக்க வந்தவ...  Non-abusive\n",
      "4  உங்களுக்கு எ‌ல்லா‌ம் சிலை தான் வைக்கணும் நாட்ட...  Non-abusive\n",
      "\n",
      "Cleaned No Punctuation dataset saved to: C:\\Users\\revan\\preprocessed_AWT_train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "data = pd.read_csv(\"preprocessed_AWT_train.csv\")\n",
    "def remove_punctuation(text):\n",
    "    punctuation = r\"[!@#$%^&*()≥≤?:\\\"|}{\\[\\].,/’;]\"\n",
    "    text = re.sub(punctuation, \"\", text)\n",
    "    return text\n",
    "data['Text'] = data['Text'].apply(remove_punctuation)\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "import os\n",
    "downloads_folder = os.path.expanduser('~')\n",
    "cleaned_file_path = os.path.join(downloads_folder, 'cleaned_no_punctuation_AWT_train.csv')\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\nCleaned No Punctuation dataset saved to: {preprocessed_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6472214-71a0-4a7f-9d8c-2445aae8adae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "Non-abusive    1366\n",
      "Abusive        1366\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882f6468-0f12-4b9a-b4c4-cdfe6fc0be1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text        Class\n",
      "0       கார்த்தி நா பாத்த அவன முகத்த மட்டும் பாத்துர  Non-abusive\n",
      "1  appo sri vanth உங்களுக்கு ஹெல்ப் பண்ணது எல்லாம...  Non-abusive\n",
      "2  இது ஒரு லூசு அது ஒரு லூசு இந்த ரெண்டு லூசு உங்...      Abusive\n",
      "3  என்ன மாறி யாரேல்லாம் இங்க கமெண்ட் படிக்க வந்தவ...  Non-abusive\n",
      "4  உங்களுக்கு எ‌ல்லா‌ம் சிலை தான் வைக்கணும் நாட்ட...  Non-abusive\n",
      "\n",
      "Cleaned No Repeating Words dataset saved to: C:\\Users\\revan\\preprocessed_AWT_train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "data = pd.read_csv(\"cleaned_no_punctuation_AWT_train.csv\")\n",
    "def remove_repeating_words(text):\n",
    "    text = re.sub(r'\\b(\\w+)\\s+\\1\\b', r'\\1', text)\n",
    "    return text\n",
    "    data['Text'] = data['Text'].apply(remove_repeating_words)\n",
    "print(data.head())\n",
    "\n",
    "import os\n",
    "downloads_folder = os.path.expanduser('~')\n",
    "cleaned_file_path = os.path.join(downloads_folder, 'cleaned_no_repeating_words_AWT_train.csv')\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\nCleaned No Repeating Words dataset saved to: {preprocessed_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab188d14-00f9-4386-809f-fcadc73f31f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "Non-abusive    1366\n",
      "Abusive        1366\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc879daa-ea98-432b-a158-282eb5afbcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b214b373-325b-4dab-b0c7-687778fd31ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens generated: 39143\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "data = pd.read_csv(\"cleaned_no_repeating_words_AWT_train.csv\")\n",
    "data['Tokens'] = data['Text'].apply(word_tokenize)\n",
    "total_tokens = sum(data['Tokens'].apply(len))\n",
    "print(f\"Total tokens generated: {total_tokens}\")\n",
    "data.to_csv('tokens_generated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85acc5cc-93a2-417a-94f8-51ba08ca0ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Processed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>கார்த்தி நா பாத்த அவன முகத்த மட்டும் பாத்துர</td>\n",
       "      <td>Non-abusive</td>\n",
       "      <td>['கார்த்தி', 'நா', 'பாத்த', 'அவன', 'முகத்த', '...</td>\n",
       "      <td>கார்த்தி நா பாத்த அவன முகத்த மட்டும் பாத்துர</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>appo sri vanth உங்களுக்கு ஹெல்ப் பண்ணது எல்லாம...</td>\n",
       "      <td>Non-abusive</td>\n",
       "      <td>['appo', 'sri', 'vanth', 'உங்களுக்கு', 'ஹெல்ப்...</td>\n",
       "      <td>appo sri vanth உங்களுக்கு ஹெல்ப் பண்ணது எல்லாம...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>இது ஒரு லூசு அது ஒரு லூசு இந்த ரெண்டு லூசு உங்...</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>['இது', 'ஒரு', 'லூசு', 'அது', 'ஒரு', 'லூசு', '...</td>\n",
       "      <td>லூசு லூசு ரெண்டு லூசு உங்களை வைத்து வீடியோ எடு...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>என்ன மாறி யாரேல்லாம் இங்க கமெண்ட் படிக்க வந்தவ...</td>\n",
       "      <td>Non-abusive</td>\n",
       "      <td>['என்ன', 'மாறி', 'யாரேல்லாம்', 'இங்க', 'கமெண்ட...</td>\n",
       "      <td>மாறி யாரேல்லாம் இங்க கமெண்ட் படிக்க வந்தவுங்க</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>உங்களுக்கு எ‌ல்லா‌ம் சிலை தான் வைக்கணும் நாட்ட...</td>\n",
       "      <td>Non-abusive</td>\n",
       "      <td>['உங்களுக்கு', 'எ\\u200cல்லா\\u200cம்', 'சிலை', ...</td>\n",
       "      <td>உங்களுக்கு எ‌ல்லா‌ம் சிலை வைக்கணும் நாட்டுக்கு...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text        Class  \\\n",
       "0       கார்த்தி நா பாத்த அவன முகத்த மட்டும் பாத்துர  Non-abusive   \n",
       "1  appo sri vanth உங்களுக்கு ஹெல்ப் பண்ணது எல்லாம...  Non-abusive   \n",
       "2  இது ஒரு லூசு அது ஒரு லூசு இந்த ரெண்டு லூசு உங்...      Abusive   \n",
       "3  என்ன மாறி யாரேல்லாம் இங்க கமெண்ட் படிக்க வந்தவ...  Non-abusive   \n",
       "4  உங்களுக்கு எ‌ல்லா‌ம் சிலை தான் வைக்கணும் நாட்ட...  Non-abusive   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  ['கார்த்தி', 'நா', 'பாத்த', 'அவன', 'முகத்த', '...   \n",
       "1  ['appo', 'sri', 'vanth', 'உங்களுக்கு', 'ஹெல்ப்...   \n",
       "2  ['இது', 'ஒரு', 'லூசு', 'அது', 'ஒரு', 'லூசு', '...   \n",
       "3  ['என்ன', 'மாறி', 'யாரேல்லாம்', 'இங்க', 'கமெண்ட...   \n",
       "4  ['உங்களுக்கு', 'எ\\u200cல்லா\\u200cம்', 'சிலை', ...   \n",
       "\n",
       "                                      Processed_Text  \n",
       "0       கார்த்தி நா பாத்த அவன முகத்த மட்டும் பாத்துர  \n",
       "1  appo sri vanth உங்களுக்கு ஹெல்ப் பண்ணது எல்லாம...  \n",
       "2  லூசு லூசு ரெண்டு லூசு உங்களை வைத்து வீடியோ எடு...  \n",
       "3      மாறி யாரேல்லாம் இங்க கமெண்ட் படிக்க வந்தவுங்க  \n",
       "4  உங்களுக்கு எ‌ல்லா‌ம் சிலை வைக்கணும் நாட்டுக்கு...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16157ecc-de2c-4e5c-beef-5e6bd72303f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Word  Frequency\n",
      "0          இவ        169\n",
      "1           ல         74\n",
      "2          அவ         74\n",
      "3          வர         68\n",
      "4         இவள         54\n",
      "5          அட         42\n",
      "6          பல         34\n",
      "7         mam         31\n",
      "8       madam         23\n",
      "9          அத         22\n",
      "10  interview         21\n",
      "11         இத         21\n",
      "12        உலக         19\n",
      "13    youtube         17\n",
      "14         என         15\n",
      "15    channel         15\n",
      "16         ah         15\n",
      "17    content         14\n",
      "18          ஐ         14\n",
      "19          ஏ         13\n",
      "Sentiment Distribution:\n",
      "Sentiment\n",
      "neutral     2653\n",
      "positive      55\n",
      "negative      24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "tamil_stopwords = set([\n",
    "    'ஆனால்', 'மற்றும்', 'இது', 'அந்த', 'இந்த', 'என்று', 'தான்', 'ஒரு', 'என்ன', 'எவர்',\n",
    "    'எங்கு', 'எப்படி', 'எப்போது', 'என்று', 'அவர்', 'அவர்கள்', 'அவை', 'அதை', 'நான்',\n",
    "    'நீ', 'அது', 'நாம்', 'நமது', 'உன்', 'என்', 'உங்கள்', 'எங்கள்', 'எந்த', 'அல்லது',\n",
    "    'இவை', 'இவள்', 'இவர்', 'இவ்வாறு', 'அவ்வாறு', 'ஆக', 'பின்', 'இங்கே', 'அங்கே',\n",
    "    'இப்போது', 'அப்போது', 'மிகவும்', 'வேறு', 'சிறு', 'பெரிய', 'அவை', 'அதில்', 'அல்ல',\n",
    "    'அதனால்', 'இதனால்', 'ஆகவே', 'அதற்கு', 'இதற்கு', 'எதற்கு', 'இங்கு', 'அவரது'\n",
    "])\n",
    "\n",
    "data = pd.read_csv('tokens_generated.csv')\n",
    "text_data = data['Text']\n",
    "\n",
    "stop_words = set(stopwords.words('english')).union(tamil_stopwords)\n",
    "\n",
    "all_tokens = []\n",
    "\n",
    "for text in text_data:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "word_counts = Counter(all_tokens)\n",
    "top_20_words = word_counts.most_common(20)\n",
    "\n",
    "top_20_df = pd.DataFrame(top_20_words, columns=['Word', 'Frequency'])\n",
    "print(top_20_df)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    sentiment = TextBlob(text).sentiment.polarity\n",
    "    if sentiment > 0:\n",
    "        return 'positive'\n",
    "    elif sentiment < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "data['Sentiment'] = data['Text'].apply(get_sentiment)\n",
    "\n",
    "sentiment_counts = data['Sentiment'].value_counts()\n",
    "\n",
    "print(\"Sentiment Distribution:\")\n",
    "print(sentiment_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89a75ff1-0d64-465a-a213-91518b96d2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved and training/testing sets prepared.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define Tamil stop words\n",
    "tamil_stopwords = set([\n",
    "    'ஆனால்', 'மற்றும்', 'இது', 'அந்த', 'இந்த', 'என்று', 'தான்', 'ஒரு', 'என்ன', 'எவர்',\n",
    "    'எங்கு', 'எப்படி', 'எப்போது', 'அவர்', 'அவர்கள்', 'அவை', 'அதை', 'நான்',\n",
    "    'நீ', 'அது', 'நாம்', 'நமது', 'உன்', 'என்', 'உங்கள்', 'எங்கள்', 'எந்த', 'அல்லது',\n",
    "    'இவை', 'இவள்', 'இவர்', 'இவ்வாறு', 'அவ்வாறு', 'ஆக', 'பின்', 'இங்கே', 'அங்கே',\n",
    "    'இப்போது', 'அப்போது', 'மிகவும்', 'வேறு', 'சிறு', 'பெரிய', 'அவை', 'அதில்', 'அல்ல',\n",
    "    'அதனால்', 'இதனால்', 'ஆகவே', 'அதற்கு', 'இதற்கு', 'எதற்கு', 'இங்கு', 'அவரது'\n",
    "])\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('tokens_generated.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text, stop_words):\n",
    "    tokens = text.split()  # Simple whitespace tokenizer\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stop words\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['Processed_Text'] = data['Text'].apply(lambda x: preprocess_text(x, tamil_stopwords))\n",
    "\n",
    "# Save the updated DataFrame back to the same CSV file\n",
    "data.to_csv('tokens_generated.csv', index=False)\n",
    "\n",
    "# Vectorize the preprocessed text\n",
    "vectorizer = TfidfVectorizer()  # No stop words needed here since preprocessing is done\n",
    "X_tfidf = vectorizer.fit_transform(data['Processed_Text'])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, data['Class'], test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Updated file saved and training/testing sets prepared.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70c9c9e5-125c-4e6e-b5f8-21eff733480c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Text', 'Class', 'Tokens', 'Processed_Text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1a9d90c-9f39-40bc-8fe4-3eea4afb5f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Abusive       0.66      0.62      0.64       334\n",
      " Non-abusive       0.66      0.70      0.68       349\n",
      "\n",
      "    accuracy                           0.66       683\n",
      "   macro avg       0.66      0.66      0.66       683\n",
      "weighted avg       0.66      0.66      0.66       683\n",
      "\n",
      "Accuracy: 65.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['அங', 'அத', 'அதன', 'அதற', 'அந', 'அப', 'அல', 'அவ', 'அவர', 'அவரத', 'ஆகவ', 'ஆன', 'இங', 'இத', 'இதன', 'இதற', 'இந', 'இப', 'இவ', 'இவர', 'இவள', 'உங', 'உன', 'எங', 'எதற', 'எந', 'என', 'எப', 'எவர', 'ஒர', 'கள', 'கவ', 'நமத', 'பட', 'மற', 'லத'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Define Tamil stop words\n",
    "tamil_stopwords = set([\n",
    "    'ஆனால்', 'மற்றும்', 'இது', 'அந்த', 'இந்த', 'என்று', 'தான்', 'ஒரு', 'என்ன', 'எவர்',\n",
    "    'எங்கு', 'எப்படி', 'எப்போது', 'அவர்', 'அவர்கள்', 'அவை', 'அதை', 'நான்',\n",
    "    'நீ', 'அது', 'நாம்', 'நமது', 'உன்', 'என்', 'உங்கள்', 'எங்கள்', 'எந்த', 'அல்லது',\n",
    "    'இவை', 'இவள்', 'இவர்', 'இவ்வாறு', 'அவ்வாறு', 'ஆக', 'பின்', 'இங்கே', 'அங்கே',\n",
    "    'இப்போது', 'அப்போது', 'மிகவும்', 'வேறு', 'சிறு', 'பெரிய', 'அவை', 'அதில்', 'அல்ல',\n",
    "    'அதனால்', 'இதனால்', 'ஆகவே', 'அதற்கு', 'இதற்கு', 'எதற்கு', 'இங்கு', 'அவரது'\n",
    "])\n",
    "\n",
    "# Normalize stop words for compatibility\n",
    "normalized_stop_words = {word.lower() for word in tamil_stopwords}\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('tokens_generated.csv')\n",
    "\n",
    "# Combine English and Tamil stop words\n",
    "stop_words = list(ENGLISH_STOP_WORDS.union(normalized_stop_words))\n",
    "\n",
    "# Create TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Fit and transform the processed text\n",
    "X_tfidf = vectorizer.fit_transform(data['Processed_Text'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf, data['Class'], test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22d3e692-5591-4d5b-abeb-163b89bfc069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['அதன', 'அதற', 'அந', 'அவர', 'இத', 'இதற', 'உங', 'உத', 'எத', 'எனக', 'எனவ', 'ஒர', 'கள', 'சர', 'தல', 'ரணம', 'வந'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.869\n",
      "Logistic Regression - Precision: 0.870\n",
      "Logistic Regression - Recall: 0.868\n",
      "Logistic Regression - F1 Score: 0.869\n",
      "Model and vectorizer saved.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "tamil_stopwords = [\n",
    "    'அத', 'அவ', 'ஆ', 'இ', 'உ', 'எ', 'ஒ', 'ஓ', 'ஏ', 'ஐ', 'ஃ', 'ஏன', 'ஆன', 'என', 'இதை', 'அந்த', \n",
    "    'அவர்கள்', 'உங்களின்', 'நாம்', 'நிறைய', 'எனவே', 'ஒரு', 'காரணம்', 'வந்து', 'தலைபார்க்க', 'குறைந்த', \n",
    "    'சரி', 'மேலும்', 'இதற்கு', 'அதற்கு', 'உதாரணமாக', 'அதன்', 'பிற', 'எனக்கு', 'செய்ய', 'எதுவும்', 'போது'\n",
    "]\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "combined_stopwords = list(set(ENGLISH_STOP_WORDS).union(tamil_stopwords))\n",
    "\n",
    "train_data = pd.read_csv('tokens_generated.csv')\n",
    "test_data = pd.read_csv('tokens_generated.csv')\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=combined_stopwords, ngram_range=(1, 2))\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_data['Text'])\n",
    "y_train = train_data['Class']\n",
    "X_test = vectorizer.transform(test_data['Text'])\n",
    "y_test = test_data['Class']\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "acc_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "precision_logreg = precision_score(y_test, y_pred_logreg, pos_label=\"Abusive\", average=\"binary\")\n",
    "recall_logreg = recall_score(y_test, y_pred_logreg, pos_label=\"Abusive\", average=\"binary\")\n",
    "f1_logreg = f1_score(y_test, y_pred_logreg, pos_label=\"Abusive\", average=\"binary\")\n",
    "\n",
    "cm_logreg = confusion_matrix(y_test, y_pred_logreg, labels=[\"Abusive\", \"Non-abusive\"])\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_logreg, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Abusive\", \"Non-abusive\"], yticklabels=[\"Abusive\", \"Non-abusive\"])\n",
    "plt.title('Confusion Matrix for Logistic Regression')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Logistic Regression - Accuracy: {acc_logreg:.3f}\")\n",
    "print(f\"Logistic Regression - Precision: {precision_logreg:.3f}\")\n",
    "print(f\"Logistic Regression - Recall: {recall_logreg:.3f}\")\n",
    "print(f\"Logistic Regression - F1 Score: {f1_logreg:.3f}\")\n",
    "\n",
    "joblib.dump(logreg, 'logistic_regression_model.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "print(\"Model and vectorizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07106ef6-1ec1-4659-9865-deca59321ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Abusive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['அதன', 'அதற', 'அந', 'அவர', 'இத', 'இதற', 'உங', 'உத', 'எத', 'எனக', 'எனவ', 'ஒர', 'கள', 'சர', 'தல', 'ரணம', 'வந'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf = joblib.load('logistic_regression_model.pkl')\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "tamil_sentence = [\"இவ ஒரு மானெங்கெட்ட பொறுக்கி. ஒரே ஒரு routine ஒர்க் அவளுக்கு இருக்குறது தண்ணிய போட்டுட்டு அசிங்கமா பேசுறது.\"]\n",
    "features = vectorizer.transform(tamil_sentence)\n",
    "prediction = rf.predict(features)\n",
    "print(f\"Prediction: {'Abusive' if prediction[0] == 'Abusive' else 'Non-abusive'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07780ee1-d7f7-43cc-9e1b-04c8181b6029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Accuracy: 0.905\n",
      "SVM - Precision: 0.911\n",
      "SVM - Recall: 0.897\n",
      "SVM - F1 Score: 0.904\n",
      "Model and vectorizer saved.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "svm = SVC(kernel='linear', probability=True, random_state=30)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm, pos_label=\"Abusive\", average=\"binary\")\n",
    "recall_svm = recall_score(y_test, y_pred_svm, pos_label=\"Abusive\", average=\"binary\")\n",
    "f1_svm = f1_score(y_test, y_pred_svm, pos_label=\"Abusive\", average=\"binary\")\n",
    "\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm, labels=[\"Abusive\", \"Non-abusive\"])\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Abusive\", \"Non-abusive\"], yticklabels=[\"Abusive\", \"Non-abusive\"])\n",
    "plt.title('Confusion Matrix for SVM')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print(f\"SVM - Accuracy: {acc_svm:.3f}\")\n",
    "print(f\"SVM - Precision: {precision_svm:.3f}\")\n",
    "print(f\"SVM - Recall: {recall_svm:.3f}\")\n",
    "print(f\"SVM - F1 Score: {f1_svm:.3f}\")\n",
    "\n",
    "joblib.dump(svm, 'svm_model1.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "print(\"Model and vectorizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61bf6db5-15d2-4a74-a238-cc6bd2f1a628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Abusive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['அதன', 'அதற', 'அந', 'அவர', 'இத', 'இதற', 'உங', 'உத', 'எத', 'எனக', 'எனவ', 'ஒர', 'கள', 'சர', 'தல', 'ரணம', 'வந'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf = joblib.load('svm_model1.pkl')\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "tamil_sentence = [\"இவ ஒரு மானெங்கெட்ட பொறுக்கி. ஒரே ஒரு routine ஒர்க் அவளுக்கு இருக்குறது தண்ணிய போட்டுட்டு அசிங்கமா பேசுறது.\"]\n",
    "features = vectorizer.transform(tamil_sentence)\n",
    "prediction = rf.predict(features)\n",
    "print(f\"Prediction: {'Abusive' if prediction[0] == 'Abusive' else 'Non-abusive'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e51bebfb-d9fe-4796-b158-75518ec8e1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.999\n",
      "Random Forest - Precision: 1.000\n",
      "Random Forest - Recall: 0.999\n",
      "Random Forest - F1 Score: 0.999\n",
      "Model and vectorizer saved.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, pos_label=\"Abusive\", average=\"binary\")\n",
    "recall_rf = recall_score(y_test, y_pred_rf, pos_label=\"Abusive\", average=\"binary\")\n",
    "f1_rf = f1_score(y_test, y_pred_rf, pos_label=\"Abusive\", average=\"binary\")\n",
    "\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf, labels=[\"Abusive\", \"Non-abusive\"])\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Abusive\", \"Non-abusive\"], yticklabels=[\"Abusive\", \"Non-abusive\"])\n",
    "plt.title('Confusion Matrix for Random Forest')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Random Forest - Accuracy: {acc_rf:.3f}\")\n",
    "print(f\"Random Forest - Precision: {precision_rf:.3f}\")\n",
    "print(f\"Random Forest - Recall: {recall_rf:.3f}\")\n",
    "print(f\"Random Forest - F1 Score: {f1_rf:.3f}\")\n",
    "\n",
    "joblib.dump(rf, 'random_forest_model1.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "print(\"Model and vectorizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e7c08f-7648-497d-a8d9-f223e6f37a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4063c-d9aa-483c-a418-0d0818b66766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f36e1cb7-c3c0-4e61-a2e6-42540c2c5dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 11711\n",
      "Epoch 1/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 4s/step - accuracy: 0.4839 - loss: 0.6956 - val_accuracy: 0.4771 - val_loss: 0.6938\n",
      "Epoch 2/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 3s/step - accuracy: 0.4825 - loss: 0.6945 - val_accuracy: 0.4771 - val_loss: 0.6960\n",
      "Epoch 3/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.4772 - loss: 0.6960 - val_accuracy: 0.4771 - val_loss: 0.6975\n",
      "Epoch 4/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 3s/step - accuracy: 0.4972 - loss: 0.6942 - val_accuracy: 0.4771 - val_loss: 0.6938\n",
      "Epoch 5/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 4s/step - accuracy: 0.4876 - loss: 0.6947 - val_accuracy: 0.4771 - val_loss: 0.6933\n",
      "Epoch 6/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 4s/step - accuracy: 0.5034 - loss: 0.6937 - val_accuracy: 0.4771 - val_loss: 0.6937\n",
      "Epoch 7/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 4s/step - accuracy: 0.4971 - loss: 0.6932 - val_accuracy: 0.4771 - val_loss: 0.6943\n",
      "Epoch 8/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 3s/step - accuracy: 0.4854 - loss: 0.6941 - val_accuracy: 0.4771 - val_loss: 0.6938\n",
      "Epoch 9/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - accuracy: 0.4830 - loss: 0.6938 - val_accuracy: 0.4771 - val_loss: 0.6938\n",
      "Epoch 10/10\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 4s/step - accuracy: 0.4934 - loss: 0.6934 - val_accuracy: 0.4771 - val_loss: 0.6935\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 499ms/step \n",
      "GRU Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65       261\n",
      "           1       0.00      0.00      0.00       286\n",
      "\n",
      "    accuracy                           0.48       547\n",
      "   macro avg       0.24      0.50      0.32       547\n",
      "weighted avg       0.23      0.48      0.31       547\n",
      "\n",
      "Confusion Matrix:\n",
      " [[261   0]\n",
      " [286   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\revan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\revan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('tokens_generated.csv')\n",
    "\n",
    "# Prepare features and labels\n",
    "X = data['Processed_Text'].values\n",
    "y = data['Class'].values\n",
    "\n",
    "# Remove NaN values\n",
    "X = X[~pd.isnull(X)]\n",
    "y = y[~pd.isnull(y)]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer for text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "\n",
    "# Padding sequences to fixed length\n",
    "max_len = 500\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train_sequences, padding='post', maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_sequences, padding='post', maxlen=max_len)\n",
    "\n",
    "# Adjusted class weights to be more balanced\n",
    "class_weight = {0: 1, 1: 1}\n",
    "\n",
    "# Define the GRU model\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Embedding(input_dim=vocab_size, output_dim=128))\n",
    "gru_model.add(GRU(256, return_sequences=False))\n",
    "gru_model.add(Dense(128, activation='relu'))\n",
    "gru_model.add(Dropout(0.5))\n",
    "gru_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "gru_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "gru_model.fit(X_train_pad, np.array(y_train), epochs=10, batch_size=64, validation_data=(X_test_pad, np.array(y_test)), class_weight=class_weight)\n",
    "\n",
    "# Predictions with threshold of 0.5\n",
    "y_pred_gru = gru_model.predict(X_test_pad)\n",
    "y_pred_gru = (y_pred_gru > 0.5).astype(int)  # Adjusted threshold to 0.5\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"GRU Model Evaluation:\")\n",
    "print(classification_report(y_test, y_pred_gru))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_gru))\n",
    "\n",
    "# Save the model and tokenizer\n",
    "gru_model.save('gru_model.keras')\n",
    "joblib.dump(tokenizer, 'tokenizer_AWT.pkl')\n",
    "\n",
    "print(\"Model and tokenizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16434dbf-3006-4542-b70d-3bc0de6fbe0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e2867-7f0f-4b65-9229-ff86733b41c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 11756\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 4s/step - accuracy: 0.5412 - loss: 0.6895 - val_accuracy: 0.4973 - val_loss: 0.9081\n",
      "Epoch 2/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 5s/step - accuracy: 0.8095 - loss: 0.4558 - val_accuracy: 0.6965 - val_loss: 0.7421\n",
      "Epoch 3/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 5s/step - accuracy: 0.9674 - loss: 0.1151 - val_accuracy: 0.6819 - val_loss: 1.0838\n",
      "Epoch 4/50\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('tokens_generated.csv')\n",
    "\n",
    "X = data['Text'].values \n",
    "y = data['Class'].values\n",
    "\n",
    "X = X[~pd.isnull(X)]\n",
    "y = y[~pd.isnull(y)]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "\n",
    "max_len = 500 \n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_sequences, padding='post', maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_sequences, padding='post', maxlen=max_len)\n",
    "\n",
    "bidirectional_gru_model = Sequential()\n",
    "bidirectional_gru_model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
    "bidirectional_gru_model.add(Bidirectional(GRU(256, return_sequences=False))) \n",
    "bidirectional_gru_model.add(Dense(128, activation='relu'))  \n",
    "bidirectional_gru_model.add(Dropout(0.5)) \n",
    "bidirectional_gru_model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "bidirectional_gru_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "bidirectional_gru_model.fit(X_train_pad, np.array(y_train), epochs=50, batch_size=64, validation_data=(X_test_pad, np.array(y_test)))\n",
    "\n",
    "y_pred_bidirectional_gru = bidirectional_gru_model.predict(X_test_pad)\n",
    "y_pred_bidirectional_gru = np.round(y_pred_bidirectional_gru).astype(int)\n",
    "\n",
    "print(\"Bidirectional GRU Model Evaluation:\")\n",
    "print(classification_report(y_test, y_pred_bidirectional_gru)) \n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bidirectional_gru))\n",
    "\n",
    "bidirectional_gru_model.save('bidirectional_gru_model.keras')\n",
    "\n",
    "joblib.dump(tokenizer, 'tokenizer_AWT_bidirectional_gru.pkl')\n",
    "\n",
    "print(\"Model and tokenizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9e0ad-e0db-424a-813e-2715f2e1e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('tokens_generated.csv')\n",
    "\n",
    "X = data['Text'].values \n",
    "y = data['Class'].values  \n",
    "\n",
    "X = X[~pd.isnull(X)]\n",
    "y = y[~pd.isnull(y)]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "\n",
    "max_len = 500  \n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_sequences, padding='post', maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_sequences, padding='post', maxlen=max_len)\n",
    "\n",
    "multi_dense_gru_model = Sequential()\n",
    "multi_dense_gru_model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
    "multi_dense_gru_model.add(GRU(256, return_sequences=True)) \n",
    "multi_dense_gru_model.add(Dense(128, activation='relu'))  \n",
    "multi_dense_gru_model.add(GRU(128))  \n",
    "multi_dense_gru_model.add(Dense(64, activation='relu'))  \n",
    "multi_dense_gru_model.add(Dropout(0.5)) \n",
    "multi_dense_gru_model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "multi_dense_gru_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "multi_dense_gru_model.fit(X_train_pad, np.array(y_train), epochs=10, batch_size=64, validation_data=(X_test_pad, np.array(y_test)))\n",
    "\n",
    "y_pred_multi_dense_gru = multi_dense_gru_model.predict(X_test_pad)\n",
    "y_pred_multi_dense_gru = np.round(y_pred_multi_dense_gru).astype(int)\n",
    "\n",
    "print(\"Multi-Dense GRU Model Evaluation:\")\n",
    "print(classification_report(y_test, y_pred_multi_dense_gru))  \n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_multi_dense_gru))\n",
    "\n",
    "multi_dense_gru_model.save('multi_dense_gru_model.keras')\n",
    "\n",
    "joblib.dump(tokenizer, 'tokenizer_AWT_multi_dense_gru.pkl')\n",
    "\n",
    "print(\"Model and tokenizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037e918-00fb-44eb-a66d-f3babd884f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('tokens_generated.csv')\n",
    "\n",
    "X = data['Text'].values \n",
    "y = data['Class'].values  \n",
    "\n",
    "X = X[~pd.isnull(X)]\n",
    "y = y[~pd.isnull(y)]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "\n",
    "max_len = 500  \n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_sequences, padding='post', maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_sequences, padding='post', maxlen=max_len)\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
    "lstm_model.add(LSTM(256, return_sequences=False))\n",
    "lstm_model.add(Dense(128, activation='relu'))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "lstm_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "lstm_model.fit(X_train_pad, np.array(y_train), epochs=10, batch_size=64, validation_data=(X_test_pad, np.array(y_test)))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_lstm = lstm_model.predict(X_test_pad)\n",
    "y_pred_lstm = np.round(y_pred_lstm).astype(int)  \n",
    "\n",
    "print(\"LSTM Model Evaluation:\")\n",
    "print(classification_report(y_test, y_pred_lstm))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lstm))\n",
    "\n",
    "lstm_model.save('lstm_model.keras')\n",
    "\n",
    "joblib.dump(tokenizer, 'tokenizer_AWT_lstm.pkl')\n",
    "\n",
    "print(\"Model and tokenizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dfeead-a11a-4856-b6d3-f0b97296c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('tokens_generated.csv')\n",
    "\n",
    "X = data['Text'].values  \n",
    "y = data['Class'].values  \n",
    "\n",
    "X = X[~pd.isnull(X)]\n",
    "y = y[~pd.isnull(y)]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "\n",
    "max_len = 500  \n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_sequences, padding='post', maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_sequences, padding='post', maxlen=max_len)\n",
    "\n",
    "bidirectional_lstm_model = Sequential()\n",
    "bidirectional_lstm_model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
    "bidirectional_lstm_model.add(Bidirectional(LSTM(256, return_sequences=False))) \n",
    "bidirectional_lstm_model.add(Dense(128, activation='relu'))\n",
    "bidirectional_lstm_model.add(Dropout(0.5))\n",
    "bidirectional_lstm_model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "bidirectional_lstm_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "bidirectional_lstm_model.fit(X_train_pad, np.array(y_train), epochs=10, batch_size=32, validation_data=(X_test_pad, np.array(y_test)))\n",
    "\n",
    "y_pred_bidirectional_lstm = bidirectional_lstm_model.predict(X_test_pad)\n",
    "y_pred_bidirectional_lstm = np.round(y_pred_bidirectional_lstm).astype(int)  \n",
    "\n",
    "print(\"Bidirectional LSTM Model Evaluation:\")\n",
    "print(classification_report(y_test, y_pred_bidirectional_lstm))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bidirectional_lstm))\n",
    "\n",
    "bidirectional_lstm_model.save('bidirectional_lstm_model.keras')\n",
    "\n",
    "joblib.dump(tokenizer, 'tokenizer_AWT_bidirectional_lstm.pkl')\n",
    "\n",
    "print(\"Model and tokenizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4ff6a-9554-4406-add0-67f166f861dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('tokens_generated.csv')\n",
    "\n",
    "X = data['Text'].values  \n",
    "y = data['Class'].values  \n",
    "\n",
    "X = X[~pd.isnull(X)]\n",
    "y = y[~pd.isnull(y)]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)  \n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer and Vocabulary Size\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Add 1 for padding token\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "\n",
    "# Convert text to sequences and pad them\n",
    "max_len = 500  # Adjust based on the data length\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_sequences, padding='post', maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_sequences, padding='post', maxlen=max_len)\n",
    "\n",
    "# Model Architecture (Multi-Dense LSTM Model)\n",
    "multi_dense_lstm_model = Sequential()\n",
    "multi_dense_lstm_model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
    "multi_dense_lstm_model.add(LSTM(256, return_sequences=True))  # LSTM layer with sequences returned\n",
    "multi_dense_lstm_model.add(Dense(128, activation='relu'))  # Dense layer\n",
    "multi_dense_lstm_model.add(LSTM(128))  # Another LSTM layer\n",
    "multi_dense_lstm_model.add(Dense(64, activation='relu'))  # Dense layer\n",
    "multi_dense_lstm_model.add(Dropout(0.5))  # Dropout for regularization\n",
    "multi_dense_lstm_model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "multi_dense_lstm_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "multi_dense_lstm_model.fit(X_train_pad, np.array(y_train), epochs=10, batch_size=64, validation_data=(X_test_pad, np.array(y_test)))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_multi_dense_lstm = multi_dense_lstm_model.predict(X_test_pad)\n",
    "y_pred_multi_dense_lstm = np.round(y_pred_multi_dense_lstm).astype(int)  # Convert predictions to 0 or 1\n",
    "\n",
    "print(\"Multi-Dense LSTM Model Evaluation:\")\n",
    "print(classification_report(y_test, y_pred_multi_dense_lstm))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_multi_dense_lstm))\n",
    "\n",
    "# Save the model\n",
    "multi_dense_lstm_model.save('multi_dense_lstm_model.keras')\n",
    "\n",
    "# Optionally, save the tokenizer (if needed later for inference or prediction)\n",
    "joblib.dump(tokenizer, 'tokenizer_AWT_multi_dense_lstm.pkl')\n",
    "\n",
    "print(\"Model and tokenizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bf3da-e836-4390-aa7e-967a0e72e35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92086b5-ec06-42d6-afd3-75a15e6fbb45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de20337-a13c-4d5e-a5a5-19f1884a556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformersNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.0)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.11-cp310-cp310-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp310-cp310-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading transformers-4.48.1-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.7 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.4/9.7 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.1/9.7 MB 16.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 16.3 MB/s eta 0:00:00\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading torch-2.5.1-cp310-cp310-win_amd64.whl (203.1 MB)\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 5.2/203.1 MB 24.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 8.1/203.1 MB 24.0 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 8.1/203.1 MB 24.0 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 8.1/203.1 MB 24.0 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 8.1/203.1 MB 24.0 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 9.2/203.1 MB 7.2 MB/s eta 0:00:27\n",
      "   -- ------------------------------------- 12.3/203.1 MB 8.4 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 16.3/203.1 MB 9.7 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 19.9/203.1 MB 10.7 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 24.4/203.1 MB 11.7 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 29.6/203.1 MB 13.0 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 29.9/203.1 MB 13.0 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 29.9/203.1 MB 13.0 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 29.9/203.1 MB 13.0 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 30.1/203.1 MB 9.7 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 32.2/203.1 MB 9.7 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 35.7/203.1 MB 10.1 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 39.8/203.1 MB 10.6 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 39.8/203.1 MB 10.6 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 39.8/203.1 MB 10.6 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 41.4/203.1 MB 9.5 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 45.1/203.1 MB 9.9 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 45.6/203.1 MB 9.9 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 45.6/203.1 MB 9.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 46.1/203.1 MB 8.8 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 48.8/203.1 MB 9.0 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 51.6/203.1 MB 9.2 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 54.8/203.1 MB 9.4 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 55.6/203.1 MB 9.5 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 56.1/203.1 MB 9.0 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 58.2/203.1 MB 9.0 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 60.8/203.1 MB 9.1 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 63.2/203.1 MB 9.2 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 65.8/203.1 MB 9.3 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 67.6/203.1 MB 9.3 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 70.0/203.1 MB 9.4 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 72.6/203.1 MB 9.5 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 75.2/203.1 MB 9.5 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 77.9/203.1 MB 9.6 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 80.0/203.1 MB 9.6 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 82.3/203.1 MB 9.7 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 83.9/203.1 MB 9.7 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 83.9/203.1 MB 9.7 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 83.9/203.1 MB 9.7 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 85.5/203.1 MB 9.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 87.6/203.1 MB 9.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 89.7/203.1 MB 9.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 89.7/203.1 MB 9.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 89.9/203.1 MB 8.9 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 91.2/203.1 MB 8.8 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 92.5/203.1 MB 8.8 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 94.1/203.1 MB 8.7 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 96.2/203.1 MB 8.7 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 97.5/203.1 MB 8.7 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 99.6/203.1 MB 8.7 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 100.7/203.1 MB 8.7 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 100.7/203.1 MB 8.7 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 100.7/203.1 MB 8.7 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 100.9/203.1 MB 8.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 102.2/203.1 MB 8.2 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 103.8/203.1 MB 8.2 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 105.4/203.1 MB 8.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 107.2/203.1 MB 8.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 108.8/203.1 MB 8.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 110.6/203.1 MB 8.2 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 112.5/203.1 MB 8.2 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 114.3/203.1 MB 8.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 116.1/203.1 MB 8.2 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 117.7/203.1 MB 8.2 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 119.5/203.1 MB 8.2 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 120.8/203.1 MB 8.2 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 122.7/203.1 MB 8.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 122.9/203.1 MB 8.1 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 124.0/203.1 MB 8.1 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 125.6/203.1 MB 8.1 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 126.9/203.1 MB 8.1 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 128.7/203.1 MB 8.1 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 130.3/203.1 MB 8.1 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 131.9/203.1 MB 8.1 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 133.7/203.1 MB 8.0 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 135.0/203.1 MB 8.0 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 136.8/203.1 MB 8.0 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 138.7/203.1 MB 8.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 140.2/203.1 MB 8.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 142.1/203.1 MB 8.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 143.9/203.1 MB 8.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 145.8/203.1 MB 8.1 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 147.3/203.1 MB 8.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 149.4/203.1 MB 8.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 150.7/203.1 MB 8.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 152.3/203.1 MB 8.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 154.1/203.1 MB 8.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 155.7/203.1 MB 8.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 157.8/203.1 MB 8.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 158.3/203.1 MB 8.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 158.3/203.1 MB 8.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 158.3/203.1 MB 8.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 159.1/203.1 MB 7.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 160.7/203.1 MB 7.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 162.3/203.1 MB 7.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 163.8/203.1 MB 7.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 163.8/203.1 MB 7.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.4/203.1 MB 7.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 165.2/203.1 MB 7.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 165.7/203.1 MB 7.6 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 166.7/203.1 MB 7.6 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 167.5/203.1 MB 7.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 168.3/203.1 MB 7.5 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 169.3/203.1 MB 7.5 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 170.1/203.1 MB 7.5 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 171.4/203.1 MB 7.4 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 172.5/203.1 MB 7.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 173.5/203.1 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 174.9/203.1 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 176.2/203.1 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 177.5/203.1 MB 7.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 178.8/203.1 MB 7.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 180.1/203.1 MB 7.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 181.7/203.1 MB 7.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 183.0/203.1 MB 7.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 184.0/203.1 MB 7.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 185.1/203.1 MB 7.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 186.1/203.1 MB 7.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 187.2/203.1 MB 7.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 188.2/203.1 MB 7.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 189.3/203.1 MB 7.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.1 MB 7.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 191.6/203.1 MB 7.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 192.9/203.1 MB 7.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 194.2/203.1 MB 7.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 195.3/203.1 MB 7.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 196.3/203.1 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 197.7/203.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.0/203.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  200.3/203.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  201.9/203.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 203.1/203.1 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.9/6.2 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 6.8 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.11-cp310-cp310-win_amd64.whl (442 kB)\n",
      "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading pyarrow-19.0.0-cp310-cp310-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.3/25.3 MB 6.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 3.1/25.3 MB 7.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.7/25.3 MB 7.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.0/25.3 MB 7.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.9/25.3 MB 7.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.7/25.3 MB 7.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 11.3/25.3 MB 7.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.1/25.3 MB 8.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.9/25.3 MB 8.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.8/25.3 MB 8.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.6/25.3 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.4/25.3 MB 8.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.3/25.3 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.3/25.3 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.3/25.3 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.6/25.3 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 7.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.6/2.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 6.8 MB/s eta 0:00:00\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.6/1.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp310-cp310-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.18.3-cp310-cp310-win_amd64.whl (90 kB)\n",
      "Installing collected packages: mpmath, xxhash, sympy, safetensors, pyarrow, propcache, networkx, multidict, fsspec, frozenlist, filelock, dill, async-timeout, aiohappyeyeballs, yarl, torch, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.2.0 dill-0.3.8 filelock-3.17.0 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.27.1 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 propcache-0.2.1 pyarrow-19.0.0 safetensors-0.5.2 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 transformers-4.48.1 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch scikit-learn pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9fb270-d538-41f9-b4d9-d1ee8cd6a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Multilingual BERT (mBERT) using Hugging Face Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e2f8c5-1dfc-4f6e-b3e1-9e695dc3fe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:96: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1370' max='1370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1370/1370 13:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.648387</td>\n",
       "      <td>0.634369</td>\n",
       "      <td>0.579877</td>\n",
       "      <td>0.731057</td>\n",
       "      <td>0.622611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.554655</td>\n",
       "      <td>0.742230</td>\n",
       "      <td>0.738422</td>\n",
       "      <td>0.749281</td>\n",
       "      <td>0.738931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.580413</td>\n",
       "      <td>0.734918</td>\n",
       "      <td>0.726127</td>\n",
       "      <td>0.756115</td>\n",
       "      <td>0.729575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>0.520087</td>\n",
       "      <td>0.740402</td>\n",
       "      <td>0.739670</td>\n",
       "      <td>0.747756</td>\n",
       "      <td>0.743140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>0.588435</td>\n",
       "      <td>0.753199</td>\n",
       "      <td>0.752352</td>\n",
       "      <td>0.761864</td>\n",
       "      <td>0.756144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>0.829651</td>\n",
       "      <td>0.753199</td>\n",
       "      <td>0.752932</td>\n",
       "      <td>0.752904</td>\n",
       "      <td>0.752965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>1.121187</td>\n",
       "      <td>0.755027</td>\n",
       "      <td>0.754791</td>\n",
       "      <td>0.754743</td>\n",
       "      <td>0.754859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>1.378519</td>\n",
       "      <td>0.742230</td>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.743060</td>\n",
       "      <td>0.740711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>1.532241</td>\n",
       "      <td>0.756856</td>\n",
       "      <td>0.756774</td>\n",
       "      <td>0.756825</td>\n",
       "      <td>0.757134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>1.593653</td>\n",
       "      <td>0.747715</td>\n",
       "      <td>0.746678</td>\n",
       "      <td>0.748254</td>\n",
       "      <td>0.746393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'test_loss': 1.593652606010437, 'test_accuracy': 0.7477148080438757, 'test_f1': 0.7466776739690721, 'test_precision': 0.7482535872262379, 'test_recall': 0.7463928150765606, 'test_runtime': 4.8969, 'test_samples_per_second': 111.703, 'test_steps_per_second': 1.838}\n",
      "Confusion Matrix:\n",
      " [[187  77]\n",
      " [ 61 222]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       264\n",
      "           1       0.74      0.78      0.76       283\n",
      "\n",
      "    accuracy                           0.75       547\n",
      "   macro avg       0.75      0.75      0.75       547\n",
      "weighted avg       0.75      0.75      0.75       547\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\897647993.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAIjCAYAAACgUncvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAO4hJREFUeJzt3Qd4VGXWwPEzAVIEEgQMAQnFRlEkCooRlqKsoYgg+CmKEhFBWVApIrrSRBRFVhBE2KJgAQsqKOhSBIRlCV2siKBR8okhKJKYYCjJfM95d2e+3JDAJMzcm5n5/3juJrfMnXfiYo7nPe+5Lrfb7RYAAADYLsL+twQAAIAiEAMAAHAIgRgAAIBDCMQAAAAcQiAGAADgEAIxAAAAhxCIAQAAOIRADAAAwCEEYgAAAA4hEANCxJ49e+S6666TuLg4cblcsmTJEr/e//vvvzf3nT9/vl/vG8w6duxoNgAoLwIxwI++/fZbueeee+S8886T6OhoiY2NlbZt28pzzz0nv//+e0DfOzU1VT7//HN54okn5NVXX5XWrVtLqLjzzjtNEKg/z5J+jhqE6nndpk2bVub779+/XyZOnCg7d+7004gBwDeVfbwOwGl88MEH8j//8z8SFRUl/fv3l0suuUSOHTsmGzZskNGjR8uXX34pf/vb3wLy3hqcpKWlyaOPPirDhg0LyHs0bNjQvE+VKlXECZUrV5YjR47I0qVL5eabb7acW7BggQl88/Pzy3VvDcQee+wxadSokSQlJfn8upUrV5br/QDAg0AM8IP09HTp27evCVbWrFkjdevW9Z4bOnSo7N271wRqgXLw4EHztUaNGgF7D802abDjFA1wNbv4+uuvnxSILVy4ULp37y7vvPOOLWPRgPCss86SyMhIW94PQOhiahLwg6lTp0pubq68+OKLliDM44ILLpAHHnjAu3/ixAl5/PHH5fzzzzcBhmZi/vznP8vRo0ctr9Pj119/vcmqXXnllSYQ0mnPV155xXuNTqlpAKg086YBk77OM6Xn+b4ofY1eV9SqVaukXbt2JpirVq2aNGnSxIzpdDViGnj+4Q9/kKpVq5rX9uzZU3bt2lXi+2lAqmPS67SWbcCAASao8dVtt90m//znP+Xw4cPeY1u3bjVTk3quuEOHDsmDDz4oLVq0MJ9Jpza7du0qn376qfeajz/+WK644grzvY7HM8Xp+ZxaA6bZze3bt0v79u1NAOb5uRSvEdPpYf1nVPzzp6SkyNlnn20ybwBQFIEY4Ac6XaYB0tVXX+3T9XfffbeMHz9eLr/8cpk+fbp06NBBpkyZYrJqxWnwctNNN8kf//hH+ctf/mJ+oWswo1Odqnfv3uYe6tZbbzX1YTNmzCjT+PVeGvBpIDhp0iTzPjfccIP8+9//PuXrPvroIxNkZGVlmWBr5MiRsnHjRpO50sCtOM1k/fbbb+az6vca7OiUoK/0s2qQ9O6771qyYU2bNjU/y+K+++47s2hBP9uzzz5rAlWto9OftycoatasmfnMavDgwebnp5sGXR6//PKLCeB02lJ/tp06dSpxfFoLeM4555iArKCgwBz761//aqYwZ82aJfXq1fP5swIIE24AZyQ7O9utf5V69uzp0/U7d+401999992W4w8++KA5vmbNGu+xhg0bmmPr16/3HsvKynJHRUW5R40a5T2Wnp5urnvmmWcs90xNTTX3KG7ChAnmeo/p06eb/YMHD5Y6bs97zJs3z3ssKSnJHR8f7/7ll1+8xz799FN3RESEu3///ie931133WW554033uiuVatWqe9Z9HNUrVrVfH/TTTe5r732WvN9QUGBOyEhwf3YY4+V+DPIz8831xT/HPrzmzRpkvfY1q1bT/psHh06dDDn5s6dW+I53YpasWKFuX7y5Mnu7777zl2tWjV3r169TvsZAYQnMmLAGcrJyTFfq1ev7tP1H374ofmq2aOiRo0aZb4WryVr3ry5mfrz0IyLThtqtsdfPLVl7733nhQWFvr0mp9++smsMtTsXM2aNb3HL730UpO983zOou69917Lvn4uzTZ5foa+0ClInU7MzMw006L6taRpSaXTvhER//nXnGao9L080647duzw+T31Pjpt6QttIaIrZzXLphk8narUrBgAlIRADDhDWnekdMrNFz/88IMJDrRurKiEhAQTEOn5oho0aHDSPXR68tdffxV/ueWWW8x0ok6Z1qlTx0yRvvXWW6cMyjzj1KCmOJ3u+/nnnyUvL++Un0U/hyrLZ+nWrZsJet98802zWlLru4r/LD10/Dpte+GFF5pgqnbt2iaQ/eyzzyQ7O9vn9zz33HPLVJivLTQ0ONVAdebMmRIfH+/zawGEFwIxwA+BmNb+fPHFF2V6XfFi+dJUqlSpxONut7vc7+GpX/KIiYmR9evXm5qvO+64wwQqGpxpZqv4tWfiTD6LhwZUmml6+eWXZfHixaVmw9STTz5pMo9a7/Xaa6/JihUrzKKEiy++2OfMn+fnUxaffPKJqZtTWpMGAKUhEAP8QIvBtZmr9vI6HV3hqEGArvQr6sCBA2Y1oGcFpD9oxqnoCkOP4lk3pVm6a6+91hS1f/XVV6YxrE79rV27ttTPoXbv3n3Sua+//tpkn3QlZSBo8KXBjmYhS1rg4PH222+bwnpdzarX6bRh586dT/qZ+BoU+0KzgDqNqVPKWvyvK2p1ZScAlIRADPCDhx56yAQdOrWnAVVxGqTpijrP1JoqvrJRAyCl/bD8Rdtj6BScZriK1nZpJql4m4fiPI1Ni7fU8NA2HXqNZqaKBjaaGdRVgp7PGQgaXGn7j+eff95M6Z4qA1c827Zo0SL58ccfLcc8AWNJQWtZjRkzRvbt22d+LvrPVNuH6CrK0n6OAMIbDV0BPwU82kZBp/O0PqpoZ31t56C//LWoXbVs2dL8YtYu+/qLX1spbNmyxfzi7tWrV6mtEcpDs0AaGNx4441y//33m55dc+bMkYsuushSrK6F5To1qUGgZrp0Wu2FF16Q+vXrm95ipXnmmWdMW4fk5GQZOHCg6byvbRq0R5i2swgUzd6NHTvWp0ylfjbNUGlrEZ0m1LoybTVS/J+f1ufNnTvX1J9pYNamTRtp3LhxmcalGUT9uU2YMMHbTmPevHmm19i4ceNMdgwALJxetgmEkm+++cY9aNAgd6NGjdyRkZHu6tWru9u2beueNWuWaaXgcfz4cdNyoXHjxu4qVaq4ExMT3Y888ojlGqWtJ7p3737atgmlta9QK1eudF9yySVmPE2aNHG/9tprJ7WvWL16tWm/Ua9ePXOdfr311lvN5yn+HsVbPHz00UfmM8bExLhjY2PdPXr0cH/11VeWazzvV7w9ht5Lj+u9fW1fUZrS2ldom4+6deua8ek409LSSmw78d5777mbN2/urly5suVz6nUXX3xxie9Z9D45OTnmn9fll19u/vkWNWLECNPSQ98bAIpy6f9YQzMAAADYgRoxAAAAhxCIAQAAOIRADAAAwCEEYgAAAA4hEAMAAHAIgRgAAIBDgrqhqz4mZv/+/aYBoz8fUQIAQCjSjlX6aDB9Pq42RrZbfn6+aXQdCJGRkRIdHS3BJqgDMQ3CEhMTnR4GAABBJSMjwzw5w+4gLKZ6LZETRwJy/4SEBElPTw+6YCyoAzHNhKn42/8mEZFnOT0cAEWsGX+d00MAUEzub7/JlS3O9/7+tJPJhJ04IlHNU0UqRfr35gXHJPOrl817EIjZyDMdqUEYgRhQsVSPjXV6CABK4Wg5T+Vocfk5EHO7yjbNOmXKFHn33Xfl66+/lpiYGPMs2qefflqaNGlizh86dMg8M3blypWyb98+Oeecc8yzgB9//HHzLF0PPTdkyBBZu3atVKtWzTxHWO9dubLv4RXF+gAAwD4aA2og6NdNymTdunUydOhQ2bRpk6xatUqOHz8u1113neTl5XlLn3SbNm2afPHFFzJ//nxZvny5DBw40HuPgoIC6d69u8nCbdy4UV5++WVz3fjx48v24wjmZ03m5OSYyDThrtfIiAEVzOYnuzk9BADF/JaTI80bxUt2drbE2py19vzOjmp5j7gqRfn13u6Co3L007+a2reinysqKspsp3Pw4EGJj483AVr79u1LvGbRokVy++23m2BNM17//Oc/5frrrzcBW506dcw1c+fOlTFjxpj76eIBX5ARAwAA9tFpxEBsImYBnwZ7nk2nCX2hgamqWbPmKa/RIM8z7ZiWliYtWrTwBmEqJSXFBJxffvlleNSIAQAAeJSUEfOlFdbw4cOlbdu2cskll5R4zc8//2zqwwYPHuw9lpmZaQnClGdfz/mKQAwAANjHU9fl73uKmCCsrFOuWiumdWAbNmwo8bxmuLQWrHnz5jJx4kTxN6YmAQBAWBo2bJgsW7bMrHosqa+aNr/t0qWLafexePFiqVKliqVv2YEDByzXe/b1nK8IxAAAQEjUiPlK1ylqEKbB1Zo1a6Rx48YlZsJ0JaUW3b///vsn9SdLTk6Wzz//XLKysrzHdAWmZuQ0e+YrpiYBAEBYGTp0qCxcuFDee+89k+3y1HRpgb/2FfMEYUeOHJHXXnvN7OumtKdYpUqVzHkNuO644w6ZOnWqucfYsWPNvX2pTfMgEAMAACFRI+arOXPmmK8dO3a0HJ83b57ceeedsmPHDtm8ebM5dsEFF1iu0ccoNWrUyARjOq2pDV01O1a1alXT0HXSpElSFgRiAADARmWfSjy9sk9NnooGaL60WW3YsKF8+OGHciaoEQMAAHAIGTEAABBWU5MVCRkxAAAAh5ARAwAA9ilHu4nT8nvNmX2Cd+QAAABBjowYAACwDzViFmTEAAAAHEJGDAAA2IcaMQsCMQAAYB+mJi2CN4QEAAAIcmTEAACAfZiatAjekQMAAAQ5MmIAAMDmGjF/Z8RcEqzIiAEAADiEjBgAALBPhOs/m7/vGaTIiAEAADiEjBgAALAPqyYtCMQAAIB9aOhqEbwhJAAAQJAjIwYAAOzD1KRF8I4cAAAgyJERAwAA9qFGzIKMGAAAgEPIiAEAAPtQI2YRvCMHAAAIcmTEAACAfagRsyAQAwAA9mFq0iJ4Rw4AABDkyIgBAAD7MDVpQUYMAADAIWTEAACAjQJQIybBm1cK3pEDAAAEOTJiAADAPtSIWZARAwAAcAgZMQAAYHNGzN99xFwSrAjEAACAfWjoahG8IwcAAAhyZMQAAIB9KNa3ICMGAADgEDJiAADAPtSIWQTvyAEAAIIcGTEAAGAfasQsyIgBAAA4hIwYAACwDzViFgRiAADAPkxNWgRvCAkAABDkCMQAAIBtXC5XQLaymDJlilxxxRVSvXp1iY+Pl169esnu3bst1+Tn58vQoUOlVq1aUq1aNenTp48cOHDAcs2+ffuke/fuctZZZ5n7jB49Wk6cOFGmsRCIAQCAsLJu3ToTZG3atElWrVolx48fl+uuu07y8vK814wYMUKWLl0qixYtMtfv379fevfu7T1fUFBggrBjx47Jxo0b5eWXX5b58+fL+PHjyzQWasQAAIBtypPBOq0y3m/58uWWfQ2gNKO1fft2ad++vWRnZ8uLL74oCxculGuuucZcM2/ePGnWrJkJ3q666ipZuXKlfPXVV/LRRx9JnTp1JCkpSR5//HEZM2aMTJw4USIjI30aCxkxAAAQEnJycizb0aNHfXqdBl6qZs2a5qsGZJol69y5s/eapk2bSoMGDSQtLc3s69cWLVqYIMwjJSXFvO+XX37p85gJxAAAgH1cAdpEJDExUeLi4ryb1oKdTmFhoQwfPlzatm0rl1xyiTmWmZlpMlo1atSwXKtBl57zXFM0CPOc95zzFVOTAAAgJGRkZEhsbKx3Pyoq6rSv0VqxL774QjZs2CBOIBADAAAhUSMWGxtrCcROZ9iwYbJs2TJZv3691K9f33s8ISHBFOEfPnzYkhXTVZN6znPNli1bLPfzrKr0XOMLpiYBAEBYta9wu90mCFu8eLGsWbNGGjdubDnfqlUrqVKliqxevdp7TNtbaLuK5ORks69fP//8c8nKyvJeoyswNRBs3ry5z2MhIwYAAMLK0KFDzYrI9957z/QS89R0aV1ZTEyM+Tpw4EAZOXKkKeDX4Oq+++4zwZeumFTa7kIDrjvuuEOmTp1q7jF27Fhzb1+mRD0IxAAAQFi1r5gzZ4752rFjR8txbVFx5513mu+nT58uERERppGrrr7UFZEvvPCC99pKlSqZac0hQ4aYAK1q1aqSmpoqkyZNKtNYCMQAAEBYcbvdp70mOjpaZs+ebbbSNGzYUD788MMzGguBGAAACKuMWEVCsT4AAIBDyIgBAAD7FGnA6jfBmxAjIwYAAOAUMmIAAMA21IhZkREDAABwCBkxAABgG01e+T8jJkGLQAwAANjGpX/8PpXokmDF1CQAAIBDyIgBAADbUKxvRUYMAADAIWTEAACAfWjoakFGDAAAwCFkxAAAgH0CUCPmpkYMAAAAZUVGDAAABPWqSVcQZ8QIxAAAgG0IxKyYmgQAAHAIGTEAAGAf2ldYkBEDAABwCBkxAABgG2rErMiIAQAAOISMGAAAsA0ZMSsyYgAAAA4hIwYAAGxDRsyKQAwAANiGQMyKqUkAAACHkBEDAAD2oaGrBRkxAAAAh5ARAwAAtqFGzIqMGAAAgEPIiAEAANuQEbMiIwYAAOAQMmIAAMA2ZMSsCMQAAIB9aF9hwdQkAACAQ8iIAQAA2zA1aUVGDAAAwCFkxAAAgG3IiFmREQMAAHAIGTEAAGAblwQgIyZkxM7I7NmzpVGjRhIdHS1t2rSRLVu2OD0kAACA0A/E3nzzTRk5cqRMmDBBduzYIS1btpSUlBTJyspyemgAACBANWL+3oKV44HYs88+K4MGDZIBAwZI8+bNZe7cuXLWWWfJSy+95PTQAABAoBq6+nsLUo4GYseOHZPt27dL586d/39AERFmPy0t7aTrjx49Kjk5OZYNAAAgWDkaiP38889SUFAgderUsRzX/czMzJOunzJlisTFxXm3xMREG0cLAADOFFOTFWxqsiweeeQRyc7O9m4ZGRlODwkAAASh9evXS48ePaRevXomkFuyZInlfG5urgwbNkzq168vMTEx3vKpovLz82Xo0KFSq1YtqVatmvTp00cOHDgQPIFY7dq1pVKlSicNWvcTEhJOuj4qKkpiY2MtGwAACB4VJSOWl5dnFghq54aS6ELC5cuXy2uvvSa7du2S4cOHm8Ds/fff914zYsQIWbp0qSxatEjWrVsn+/fvl969ewdPIBYZGSmtWrWS1atXe48VFhaa/eTkZCeHBgAAQljXrl1l8uTJcuONN5Z4fuPGjZKamiodO3Y0LbYGDx5sAjdPiy2dmXvxxRfNosNrrrnGxDPz5s0zr9u0aVPwTE1qxPn3v/9dXn75ZRNxDhkyxESpuooSAACEFk1eBWJTxRf06SK/8rr66qtN9uvHH38Ut9sta9eulW+++Uauu+46c14XGx4/ftyy4LBp06bSoEGDEhccVtjO+rfccoscPHhQxo8fbwr0k5KSTCqweAE/AADAqRRfxKc9SidOnCjlMWvWLJMF0xqxypUrm64Omjhq3769Oa8xi87s1ahRw6cFhxU2EFM656obAAAIbf/JYPn7od9i6CK+ovXjWlteXhqI6RSjZsUaNmxoivu1MF+L+4tmwc5UhQjEAABAmCgyleg3/72fvxby/f777/LnP/9ZFi9eLN27dzfHLr30Utm5c6dMmzbNBGK6qFD7oR4+fNiSFSttwWGFrREDAACoSLT2SzedjixKOz3ookKlxflVqlSxLDjcvXu37Nu3r0wLDsmIAQAA2wSiAaurHPfTPmF79+717qenp5uMV82aNU3BfYcOHWT06NGmh5hOTWp7ildeecWsklTaWH7gwIFm0aG+RjNx9913nwnCrrrqKp/HQSAGAADCzrZt26RTp07efQ2olLasmD9/vrzxxhumkXy/fv3k0KFDJhh74okn5N577/W+Zvr06SZrpo1cdYVmSkqKvPDCC2UaB4EYAACwTdF2E/5SnvtpfzBtS1EarfPSvmCnEh0dbRrCltYU1hfUiAEAADiEjBgAALBNRITLbP7k9vP97ERGDAAAwCFkxAAAQNjViFUUBGIAACDs2ldUFExNAgAAOISMGAAAsA1Tk1ZkxAAAABxCRgwAANiGGjErMmIAAAAOISMGAABsQ0bMiowYAACAQ8iIAQAA27Bq0opADAAA2MYlAZialOCNxJiaBAAAcAgZMQAAYBumJq3IiAEAADiEjBgAALAN7SusyIgBAAA4hIwYAACwDTViVmTEAAAAHEJGDAAA2IYaMSsyYgAAAA4hIwYAAGxDjZgVgRgAALANU5NWTE0CAAA4hIwYAACwTwCmJiV4E2JkxAAAAJxCRgwAANiGGjErMmIAAAAOISMGAABsQ/sKKzJiAAAADiEjBgAAbEONmBWBGAAAsA1Tk1ZMTQIAADiEjBgAALANU5NWZMQAAAAcQkYMAADYhoyYFRkxAAAAh5ARAwAAtmHVpBUZMQAAAIeQEQMAALahRsyKQAwAANiGqUkrpiYBAAAcQkYMAADYhqlJKzJiAAAADiEjBgAAbKO5K7/XiEnwIiMGAADCzvr166VHjx5Sr149M7W5ZMmSk67ZtWuX3HDDDRIXFydVq1aVK664Qvbt2+c9n5+fL0OHDpVatWpJtWrVpE+fPnLgwIEyjYNADAAA2CbC5QrIVlZ5eXnSsmVLmT17donnv/32W2nXrp00bdpUPv74Y/nss89k3LhxEh0d7b1mxIgRsnTpUlm0aJGsW7dO9u/fL7179y7TOJiaBAAAYadr165mK82jjz4q3bp1k6lTp3qPnX/++d7vs7Oz5cUXX5SFCxfKNddcY47NmzdPmjVrJps2bZKrrrrKp3GQEQMAALb3EfP3pnJycizb0aNHpTwKCwvlgw8+kIsuukhSUlIkPj5e2rRpY5m+3L59uxw/flw6d+7sPabZswYNGkhaWprP70UgBgAAbG9f4e9NJSYmmnouzzZlyhQpj6ysLMnNzZWnnnpKunTpIitXrpQbb7zRTDvqFKTKzMyUyMhIqVGjhuW1derUMed8xdQkAAAICRkZGRIbG+vdj4qKKndGTPXs2dPUgamkpCTZuHGjzJ07Vzp06OCnEROIAQAAG0W4/rP5+55Kg7CigVh51a5dWypXrizNmze3HNf6rw0bNpjvExIS5NixY3L48GFLVkxXTeo5XzE1CQAAUIROOWqrit27dxc9LN988400bNjQfN+qVSupUqWKrF692nter9f2FsnJyeIrMmIAAMA+prje+Y6uubm5snfvXu9+enq67Ny5U2rWrGkK7kePHi233HKLtG/fXjp16iTLly83rSq0lYXSGrSBAwfKyJEjzWs0E3ffffeZIMzXFZOKQAwAAISdbdu2mQDLQwMqlZqaKvPnzzfF+VoPpgX/999/vzRp0kTeeecd01vMY/r06RIREWEaueoKTV1h+cILL5RpHARiAADANkXbTfhLee7XsWNHcbvdp7zmrrvuMltptLmrNoQtrSmsL6gRAwAAcAgZMQAAYBvXf//4+57BikAMAACERPuKYMTUJAAAgEPIiAEAANsUfSSRv/i9HYaNyIgBAAA4hIwYAAAIu/YVFQUZMQAAAIeQEQMAALaJcLnM5u97BisyYgAAAA4hIwYAAGxDjZgVgRgAALAN7SvKEYh99tln4qtLL73U52sBAADCmU+BWFJSkok2S3tKueecfi0oKPD3GAEAQIhgarIcgVh6erovlwEAAMDfgVjDhg3Lck8AAIAS0b7CD+0rXn31VWnbtq3Uq1dPfvjhB3NsxowZ8t5775XndgAAAGGpzIHYnDlzZOTIkdKtWzc5fPiwtyasRo0aJhgDAAAojStAW9gEYrNmzZK///3v8uijj0qlSpW8x1u3bi2ff/65v8cHAAAQssrcR0wL9y+77LKTjkdFRUleXp6/xgUAAEIQfcTOMCPWuHFj2blz50nHly9fLs2aNSvr7QAAQBiJcAVmC5uMmNaHDR06VPLz803vsC1btsjrr78uU6ZMkX/84x+BGSUAAEAIKnMgdvfdd0tMTIyMHTtWjhw5IrfddptZPfncc89J3759AzNKAAAQEpia9MOzJvv162c2DcRyc3MlPj6+PLcBAAAIa+V+6HdWVpbs3r3bG4mec845/hwXAAAIUUGcwHK+WP+3336TO+64w0xHdujQwWz6/e233y7Z2dn+HyEAAECIiihPjdjmzZvlgw8+MA1ddVu2bJls27ZN7rnnnsCMEgAAhFSNmL+3sJma1KBrxYoV0q5dO++xlJQU0+S1S5cu/h4fAABAyCpzIFarVi2Ji4s76bgeO/vss/01LgAAEIIC0fcrwhVGU5PatkJ7iWVmZnqP6fejR4+WcePG+Xt8AAAghDA1WY6MmD7SqOiH3LNnjzRo0MBsat++feYRRwcPHqRODAAAwJ+BWK9evXy9HwAAQKk0rePv/JVLQjwQmzBhQuBHAgAAEGbK3dAVAACgrCJcLrP5+55hE4gVFBTI9OnT5a233jK1YceOHbOcP3TokD/HBwAAELLKvGrysccek2effVZuueUW00lfV1D27t1bIiIiZOLEiYEZJQAACAmavArEFjaB2IIFC0zz1lGjRknlypXl1ltvlX/84x8yfvx42bRpU2BGCQAAEILKHIhpz7AWLVqY76tVq+Z9vuT1119vHnsEAABQGvqInWEgVr9+ffnpp5/M9+eff76sXLnSfL9161bTSwwAAAABCsRuvPFGWb16tfn+vvvuM930L7zwQunfv7/cddddZb0dAAAII9SIneGqyaeeesr7vRbsN2zYUDZu3GiCsR49epT1dgAAIIzQvuIMM2LFXXXVVWblZJs2beTJJ58809sBAACEjTMOxDy0boyHfgMAgFNhajJAgRgAAADKhkccAQAA2wSi3YQriFNiIRGIffpMD4mNjXV6GACKOPuKYU4PAUAx7gLrYwkRRIGYFuSfysGDB/0xHgAAEMIiAlAXFVGO16xfv16eeeYZ2b59u6lzX7x4sfTq1avEa++9917561//ap61PXz4cMvztbWV19KlS82jHvv06SPPPfecaXjv90Dsk08+Oe017du39/mNAQAAnJKXlyctW7Y0PVD1mdml0QBNH+FYr169k87169fPBHGrVq2S48ePy4ABA2Tw4MGycOFC/wdia9eu9fmmAAAAFblGrGvXrmY7lR9//NFkvFasWCHdu3e3nNu1a5csX77cPFmodevW5tisWbOkW7duMm3atBIDt5KwahIAANhGY6YIP2+u/8ZhOTk5lu3o0aPlHmdhYaHccccdMnr0aLn44otPOp+WliY1atTwBmGqc+fOZopy8+bNPr8PgRgAAAgJiYmJEhcX592mTJlS7ns9/fTTUrlyZbn//vtLPJ+ZmSnx8fGWY3p9zZo1zbmwWjUJAACCgyeL5e97qoyMDEsXhaioKCkPLeDXovsdO3YEvDUGGTEAABASYmNjLVt5A7F//etfkpWVJQ0aNDBZLt1++OEHGTVqlDRq1Mhck5CQYK4p6sSJE2YlpZ7zFRkxAAAQdsX6p6K1YVrvVVRKSoo5risjVXJyshw+fNhkz1q1amWOrVmzxtSW6fO3AxqIaaSo/TS+/fZbefvtt+Xcc8+VV199VRo3bizt2rUrzy0BAABsk5ubK3v37vXup6eny86dO02Nl2bCatWqZbm+SpUqJtPVpEkTs9+sWTPp0qWLDBo0SObOnWvaVwwbNkz69u3r84rJck1NvvPOOyYqjImJMb3FPCsSsrOz5cknnyzr7QAAQBjx94rJiHLWnG3btk0uu+wys3ka1+v348eP9/keCxYskKZNm8q1115r2lZoMupvf/tbmcZR5ozY5MmTTeTXv39/eeONN7zH27Zta84BAABUdB07dhS32+3z9d9///1JxzR7VpbmrX4JxHbv3l1iB31dJqpzpQAAAKXRci5/L0R0Be8zv8s+Nanzo0XnVD02bNgg5513nr/GBQAAQlCEyxWQLWwCMS1Ke+CBB0zXWF2lsH//fjNH+uCDD8qQIUMCM0oAAIAQVOapyYcfftgszdTCtCNHjphpSu3ToYGYPo8JAADgVBkgfzcxjZAwCsQ0C/boo4+aZy/pFKUu/2zevLlUq1YtMCMEAAAIUeVu6BoZGWkCMAAAAF9RrH+GgVinTp1O2cFWu8oCAAAgAIFYUlKSZV87yWon2i+++EJSU1PLejsAABBGIsT/qxwjxBU+gdj06dNLPD5x4kRTLwYAAACbFxrcfvvt8tJLL/nrdgAAIIRrxPy9hV2xfnFpaWkSHR3tr9sBAIAQVN5nQ56Kv+9XoQOx3r17W/b1OU0//fSTeXjmuHHj/Dk2AACAkFbmQEyfKVlURESENGnSRCZNmiTXXXedP8cGAABCjE4j+rtY3xUuGbGCggIZMGCAtGjRQs4+++zAjQoAACAMlKlYv1KlSibrdfjw4cCNCAAAhCyK9c9w1eQll1wi3333XVlfBgAAgDMNxCZPnmwe8L1s2TJTpJ+Tk2PZAAAATrdq0t9byNeIaTH+qFGjpFu3bmb/hhtusDzqSFdP6r7WkQEAAMCPgdhjjz0m9957r6xdu9bXlwAAAFi4/vvH3/cM+UBMM16qQ4cOgRwPAAAIYTR0PYMasaJTkQAAALCxj9hFF1102mDs0KFDZzgkAAAQqsiInUEgpnVixTvrAwAAwIZArG/fvhIfH1/OtwIAAOFOZ9b8XerkCuLSqYhw+JAAAAAhsWoSAACgvKgRK2cgVlhY6OulAAAA8HeNGAAAwJkIxEO6XeGQEQMAADhTES6X2fx9z7B56DcAAAD8g4wYAACwDcX6VmTEAAAAHEJGDAAA2CcAxfpCRgwAAABlRUYMAADYJkJcZvP3PYMVGTEAAACHkBEDAAC2oaGrFYEYAACwDe0rrJiaBAAAcAgZMQAAYBsecWRFRgwAAMAhZMQAAIBtKNa3IiMGAADgEDJiAADA3oau/q4Rk+BNiZERAwAAcAgZMQAAYBtqxKwIxAAAgK1Tcf6ejouQ4BXMYwcAACiX9evXS48ePaRevXricrlkyZIl3nPHjx+XMWPGSIsWLaRq1armmv79+8v+/fst9zh06JD069dPYmNjpUaNGjJw4EDJzc0t0zgIxAAAgG006AnEVlZ5eXnSsmVLmT179knnjhw5Ijt27JBx48aZr++++67s3r1bbrjhBst1GoR9+eWXsmrVKlm2bJkJ7gYPHlymcTA1CQAAQkJOTo5lPyoqymwl6dq1q9lKEhcXZ4Krop5//nm58sorZd++fdKgQQPZtWuXLF++XLZu3SqtW7c218yaNUu6desm06ZNM1k0X5ARAwAAtnEFaFOJiYkmiPJsU6ZMEX/Jzs42mTedglRpaWnme08Qpjp37iwRERGyefNmn+9LRgwAAISEjIwMU6/lUVo2rKzy8/NNzditt97qvX9mZqbEx8dbrqtcubLUrFnTnPMVgRgAAAiJh37HxsZaAjF/0ML9m2++Wdxut8yZM0f8jUAMAADgFEHYDz/8IGvWrLEEeQkJCZKVlWW5/sSJE2YlpZ7zFTViAADAVoGoDwtUELZnzx756KOPpFatWpbzycnJcvjwYdm+fbv3mAZrhYWF0qZNG5/fh4wYAAAIu876ubm5snfvXu9+enq67Ny509R41a1bV2666SbTukLbUhQUFHjrvvR8ZGSkNGvWTLp06SKDBg2SuXPnmsBt2LBh0rdvX59XTCoCMQAAEHa2bdsmnTp18u6PHDnSfE1NTZWJEyfK+++/b/aTkpIsr1u7dq107NjRfL9gwQITfF177bVmtWSfPn1k5syZZRoHgRgAALBNeRuwnkp57qfBlBbgl+ZU5zw0O7Zw4UI5E9SIAQAAOISMGAAAsA0P/Q6dsQMAAAQ1MmIAACDsasQqCjJiAAAADiEjBgAAbBOIJqwuCV5kxAAAABxCRgwAANiGGjErAjEAAGAb2leEztgBAACCGhkxAABgG6YmrciIAQAAOISMGAAAsA3tK6zIiAEAADiEjBgAALCNlnP5u6TLFcQpMTJiAAAADiEjBgAAbBMhLrP5+57BikAMAADYhqlJK6YmAQAAHEJGDAAA2Mb13z/+vmewIiMGAADgEDJiAADANtSIWZERAwAAcAgZMQAAYBut5/J3uwkXNWIAAAAoKzJiAADANtSIWRGIAQAA2xCIWTE1CQAA4BAyYgAAwDY0dLUiIwYAAOAQMmIAAMA2Ea7/bP6+Z7AiIwYAAOAQMmIAAMA21IhZkREDAABwCBkxAABgG/qIWRGIAQAA22jM5P+pyeDF1CQAAIBDyIgBAADb0L7CiowYAACAQ8iIAQAA29C+woqMGAAAgEPIiAEAANvQvqICZcTWr18vPXr0kHr16onL5ZIlS5Y4ORwAAIDwCcTy8vKkZcuWMnv2bCeHAQAAbO0j5v8tWDk6Ndm1a1ezAQCA8BAhLonw81xiRBCHYkFVI3b06FGzeeTk5Dg6HgAAgLBZNTllyhSJi4vzbomJiU4PCQAABOHU5PrT1Km73W4ZP3681K1bV2JiYqRz586yZ88eyzWHDh2Sfv36SWxsrNSoUUMGDhwoubm5oRuIPfLII5Kdne3dMjIynB4SAAAIQnmnqVOfOnWqzJw5U+bOnSubN2+WqlWrSkpKiuTn53uv0SDsyy+/lFWrVsmyZctMcDd48ODQnZqMiooyGwAACFKBqK53+bdOXbNhM2bMkLFjx0rPnj3NsVdeeUXq1KljMmd9+/aVXbt2yfLly2Xr1q3SunVrc82sWbOkW7duMm3aNJNpC7mMGAAAQGm0drzoVrSuvCzS09MlMzPTTEd6aElUmzZtJC0tzezrV52O9ARhSq+PiIgwGTRfORqI6Tzqzp07zeb54Pr9vn37nBwWAAAI8COO/P1Hae140VpyrS0vDw3ClGbAitJ9zzn9Gh8fbzlfuXJlqVmzpveaCj81uW3bNunUqZN3f+TIkeZramqqzJ8/38GRAQCAYJORkWEK5z2CoZzJ0UCsY8eOZh4WAACEiQA84kj+ez8NwooGYuWVkJBgvh44cMCsmvTQ/aSkJO81WVlZltedOHHCrKT0vN4X1IgBAICwa19xKo0bNzbB1OrVq73HtOZMa7+Sk5PNvn49fPiwbN++3XvNmjVrpLCw0NSSheSqSQAAAH/Vqe/du9e776lT1xqvBg0ayPDhw2Xy5Mly4YUXmsBs3LhxZiVkr169zPXNmjWTLl26yKBBg0yLi+PHj8uwYcPMikpfV0wqAjEAABB27Su2naZO/aGHHjK9xrQvmGa+2rVrZ9pVREdHe1+zYMECE3xde+21ZrVknz59TO+xMg3dHcRFWpom1FURB37J9sucMAD/OfuKYU4PAUAx7oJjcvTzv5um6Hb/3vT8zl7z6T6pVt2/7537W45c07KBI5/rTJERAwAAtinabsJf/H0/O1GsDwAA4BAyYgAAwDauALSvcAVvQoyMGAAAgFPIiAEAgHBbNFlhEIgBAAD7EIlZMDUJAADgEDJiAADANrSvsCIjBgAA4BAyYgAAwDa0r7AiIwYAAOAQMmIAAMA2LJq0IiMGAADgEDJiAADAPqTELAjEAACAbWhfYcXUJAAAgEPIiAEAANvQvsKKjBgAAIBDyIgBAADbUKtvRUYMAADAIWTEAACAfUiJWZARAwAAcAgZMQAAYBv6iFmREQMAAHAIGTEAAGAb+ohZEYgBAADbUKtvxdQkAACAQ8iIAQAA+5ASsyAjBgAA4BAyYgAAwDa0r7AiIwYAAOAQMmIAAMA2tK+wIiMGAADgEDJiAADANiyatCIQAwAA9iESs2BqEgAAwCFkxAAAgG1oX2FFRgwAAMAhZMQAAIB9AtC+QoI3IUZGDAAAwClkxAAAgG1YNGlFRgwAAMAhZMQAAIB9SIlZEIgBAADb0L7CiqlJAAAAh5ARAwAAtnEFoH2FK3gTYmTEAABAeCkoKJBx48ZJ48aNJSYmRs4//3x5/PHHxe12e6/R78ePHy9169Y113Tu3Fn27Nnj97EQiAEAANtr9f29lcXTTz8tc+bMkeeff1527dpl9qdOnSqzZs3yXqP7M2fOlLlz58rmzZulatWqkpKSIvn5+eJPTE0CAICwsnHjRunZs6d0797d7Ddq1Ehef/112bJlizcbNmPGDBk7dqy5Tr3yyitSp04dWbJkifTt29dvYyEjBgAAQiIllpOTY9mOHj1a4hCuvvpqWb16tXzzzTdm/9NPP5UNGzZI165dzX56erpkZmaa6UiPuLg4adOmjaSlpfn1x0FGDAAAhITExETL/oQJE2TixIknXffwww+bQK1p06ZSqVIlUzP2xBNPSL9+/cx5DcKUZsCK0n3POX8hEAMAACHRRywjI0NiY2O9x6Oiokq8/q233pIFCxbIwoUL5eKLL5adO3fK8OHDpV69epKamip2IhADAAC2MTOJ/m5fIf+hQVjRQKw0o0ePNlkxT61XixYt5IcffpApU6aYQCwhIcEcP3DggFk16aH7SUlJfh07NWIAACCsHDlyRCIirCGQTlEWFhaa77WthQZjWkfmoVOZunoyOTnZr2MhIwYAAMLqUZM9evQwNWENGjQwU5OffPKJPPvss3LXXXf9534ul5mqnDx5slx44YUmMNO+Yzp12atXL7+OnUAMAACElVmzZpnA6k9/+pNkZWWZAOuee+4xDVw9HnroIcnLy5PBgwfL4cOHpV27drJ8+XKJjo7261hc7qJtZIOMpgl1OemBX7J9mhMGYJ+zrxjm9BAAFOMuOCZHP/+7ZGfb/3vT8zv7q++zpLqf3/u3nBxp3ijekc91pqgRAwAAcAhTkwAAIMyqxCoOMmIAAAAOISMGAABsoz3E/N5HzCVBi0AMAADYholJK6YmAQAAHEJGDAAA2IapSSsyYgAAAA4hIwYAAGzj+u8ff98zWJERAwAAcAgZMQAAYB+WTVqQEQMAAHAIGTEAAGAbEmJWBGIAAMA2tK+wYmoSAADAIWTEAACAbWhfYUVGDAAAwCFkxAAAgH2o1rcgIwYAAOAQMmIAAMA2JMSsyIgBAAA4hIwYAACwDX3ErAjEAACAjfzfvkKCeHKSqUkAAACHkBEDAAC2YWrSiowYAACAQwjEAAAAHEIgBgAA4BBqxAAAgG2oEbMiIwYAAOAQMmIAAMDmLmL+TWG5griPGIEYAACwDVOTVkxNAgAAOISMGAAAsI0mr3jA0f8jIwYAAOAQMmIAAMA+pMQsyIgBAAA4hIwYAACwDe0rrMiIAQAAOISMGAAAsA19xKzIiAEAADiEjBgAALANiyatCMQAAIB9iMQsmJoEAABwCBkxAABgG9pXWJERAwAAcAgZMQAAYBvaV4RQIOZ2u83X33JynB4KgGLcBcecHgKAUv5een5/OiEnAL+zc4I4DgjqQOy3334zXy9onOj0UAAACKrfn3Fxcba+Z2RkpCQkJMiFAfqdnZCQYN4j2LjcTobFZ6iwsFD2798v1atXF1cw5yXh/S+axMREycjIkNjYWKeHA+C/+LsZOvRXvgZh9erVk4gI+8vE8/Pz5dixwGTLIyMjJTo6WoJNUGfE9P9E9evXd3oY8DP9Fz3/sgcqHv5uhga7M2FFaaAUjMFSILFqEgAAwCEEYgAAAA4hEEOFERUVJRMmTDBfAVQc/N0EAieoi/UBAACCGRkxAAAAhxCIAQAAOIRADAAAwCEEYgAAAA4hEEOFMHv2bGnUqJFp9NemTRvZsmWL00MCwt769eulR48epgu7Pr1kyZIlTg8JCDkEYnDcm2++KSNHjjTL43fs2CEtW7aUlJQUycrKcnpoQFjLy8szfx/1P5QABAbtK+A4zYBdccUV8vzzz3ufIarPtbvvvvvk4Ycfdnp4APSXhcslixcvll69ejk9FCCkkBGDo/Thr9u3b5fOnTtbniGq+2lpaY6ODQCAQCMQg6N+/vlnKSgokDp16liO635mZqZj4wIAwA4EYgAAAA4hEIOjateuLZUqVZIDBw5Yjut+QkKCY+MCAMAOBGJwVGRkpLRq1UpWr17tPabF+rqfnJzs6NgAAAi0ygF/B+A0tHVFamqqtG7dWq688kqZMWOGWTY/YMAAp4cGhLXc3FzZu3evdz89PV127twpNWvWlAYNGjg6NiBU0L4CFYK2rnjmmWdMgX5SUpLMnDnTtLUA4JyPP/5YOnXqdNJx/Q+n+fPnOzImINQQiAEAADiEGjEAAACHEIgBAAA4hEAMAADAIQRiAAAADiEQAwAAcAiBGAAAgEMIxAAAABxCIAYAAOAQAjEgzNx5553Sq1cv737Hjh1l+PDhjnRtd7lccvjwYds+a0UdJ4DwRSAGVAAaMOgve930QegXXHCBTJo0SU6cOBHw93733Xfl8ccfr5BBSaNGjcyzRwEgVPHQb6CC6NKli8ybN0+OHj0qH374oQwdOlSqVKkijzzyyEnXHjt2zARs/qAPcAYAOIOMGFBBREVFSUJCgjRs2FCGDBkinTt3lvfff98yxfbEE09IvXr1pEmTJuZ4RkaG3HzzzVKjRg0TUPXs2VO+//577z0LCgpk5MiR5nytWrXkoYcekuKPly0+NamB4JgxYyQxMdGMSbNzL774ormv5wHQZ599tsmM6bhUYWGhTJkyRRo3biwxMTHSsmVLefvtty3vo8HlRRddZM7rfYqOszz0sw0cOND7nvozee6550q89rHHHpNzzjlHYmNj5d577zWBrIcvYweAQCEjBlRQGhT88ssv3v3Vq1ebQGLVqlVm//jx45KSkiLJycnyr3/9SypXriyTJ082mbXPPvvMZMz+8pe/yPz58+Wll16SZs2amf3FixfLNddcU+r79u/fX9LS0mTmzJkmKElPT5eff/7ZBGbvvPOO9OnTR3bv3m3GomNUGsi89tprMnfuXLnwwgtl/fr1cvvtt5vgp0OHDiZg7N27t8nyDR48WLZt2yajRo06o5+PBlD169eXRYsWmSBz48aN5t5169Y1wWnRn1t0dLSZVtXgb8CAAeZ6DWp9GTsABJQbgONSU1PdPXv2NN8XFha6V61a5Y6KinI/+OCD3vN16tRxHz161PuaV1991d2kSRNzvYeej4mJca9YscLs161b1z116lTv+ePHj7vr16/vfS/VoUMH9wMPPGC+3717t6bLzPuXZO3ateb8r7/+6j2Wn5/vPuuss9wbN260XDtw4ED3rbfear5/5JFH3M2bN7ecHzNmzEn3Kq5hw4bu6dOnu301dOhQd58+fbz7+nOrWbOmOy8vz3tszpw57mrVqrkLCgp8GntJnxkA/IWMGFBBLFu2TKpVq2YyXZrtue2222TixIne8y1atLDUhX366aeyd+9eqV69uuU++fn58u2330p2drb89NNP0qZNG+85zZq1bt36pOlJj507d0qlSpXKlAnSMRw5ckT++Mc/Wo7r9N9ll11mvt+1a5dlHEozeWdq9uzZJtu3b98++f333817JiUlWa7RrN5ZZ51led/c3FyTpdOvpxs7AAQSgRhQQWjd1Jw5c0ywpXVgGjQVVbVqVcu+BhGtWrWSBQsWnHQvnVYrD89UY1noONQHH3wg5557ruWc1pgFyhtvvCEPPvigmW7V4EoD0meeeUY2b95c4ccOAB4EYkAFoYGWFsb76vLLL5c333xT4uPjTb1WSbReSgOT9u3bm31th7F9+3bz2pJo1k2zcevWrTOLBYrzZOS0UN6jefPmJmjRrFRpmTStT/MsPPDYtGmTnIl///vfcvXVV8uf/vQn7zHNBBanmUPNlnmCTH1fzTxqzZsucDjd2AEgkFg1CQSpfv36Se3atc1KSS3W16J6LUi///775X//93/NNQ888IA89dRTsmTJEvn6669N0HKqHmDatys1NVXuuusu8xrPPd966y1zXld06mpJnUY9ePCgyShpJkozUyNGjJCXX37ZBEM7duyQWbNmmX2lKxX37Nkjo0ePNoX+CxcuNIsIfPHjjz+aKdOi26+//moK67Xof8WKFfLNN9/IuHHjZOvWrSe9XqcZdXXlV199ZVZuTpgwQYYNGyYRERE+jR0AAspv1WYA/FKsX5bzP/30k7t///7u2rVrm+L+8847zz1o0CB3dna2tzhfC/FjY2PdNWrUcI8cOdJcX1qxvvr999/dI0aMMIX+kZGR7gsuuMD90ksvec9PmjTJnZCQ4Ha5XGZcShcMzJgxwyweqFKlivucc85xp6SkuNetW+d93dKlS829dJx/+MMfzD19KdbXa4pvulBBC+3vvPNOd1xcnPlsQ4YMcT/88MPuli1bnvRzGz9+vLtWrVqmSF9/Pvpaj9ONnWJ9AIHk0v8JbKgHAACAkjA1CQAA4BACMQAAAIcQiAEAADiEQAwAAMAhBGIAAAAOIRADAABwCIEYAACAQwjEAAAAHEIgBgAA4BACMQAAAIcQiAEAAIgz/g9KSabnmqWtvwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load CSV Dataset with Custom Columns\n",
    "def load_data(csv_path):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    X = data['Processed_Text'].values  # Feature column\n",
    "    y = data['Class'].values           # Label column\n",
    "    return X, y\n",
    "\n",
    "# 2. Tokenizer Setup\n",
    "def tokenize_data(texts, tokenizer, max_len=128):\n",
    "    return tokenizer(list(texts), padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "\n",
    "# 3. Dataset Class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# 4. Metrics Calculation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    report = classification_report(labels, preds, output_dict=True)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': report['macro avg']['f1-score'],\n",
    "        'precision': report['macro avg']['precision'],\n",
    "        'recall': report['macro avg']['recall'],\n",
    "    }\n",
    "\n",
    "# 5. Plot Confusion Matrix\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(set(y_true)))\n",
    "    plt.xticks(tick_marks, tick_marks)\n",
    "    plt.yticks(tick_marks, tick_marks)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# 6. Train and Evaluate Model\n",
    "def train_and_evaluate(csv_path, save_path):\n",
    "    # Load and preprocess data\n",
    "    texts, labels = load_data(csv_path)\n",
    "\n",
    "    # Encode labels to numeric values\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "    encodings = tokenize_data(texts, tokenizer)\n",
    "    dataset = CustomDataset(encodings, labels)\n",
    "\n",
    "    # Split dataset into train/test\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Load pre-trained model\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(set(labels)))\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "    )\n",
    "\n",
    "    # Trainer setup\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "\n",
    "    # Evaluate the model\n",
    "    preds = trainer.predict(test_dataset)\n",
    "    print(\"Metrics:\", preds.metrics)\n",
    "\n",
    "    # Confusion Matrix and Classification Report\n",
    "    labels_test = [item['labels'].item() for item in test_dataset]\n",
    "    preds_labels = np.argmax(preds.predictions, axis=1)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(labels_test, preds_labels))\n",
    "    print(\"Classification Report:\\n\", classification_report(labels_test, preds_labels))\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix(labels_test, preds_labels)\n",
    "\n",
    "# 7. Main Execution\n",
    "csv_path = \"tokens_generated.csv\"  # Replace with your CSV file path\n",
    "save_path = \"./saved_model_tenEpochs\"        # Path to save the trained model\n",
    "train_and_evaluate(csv_path, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82ef247-52a1-458d-846c-3b9bd2110193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.1/2.3 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 10.2 MB/s eta 0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "babc6b21-ab0b-4127-897b-18a584f46040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (6.1.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers[torch]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c1b01c-c347-447d-86f6-45cce46e123f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl.metadata (8.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 786.4/991.5 kB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 7.8 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\varun balaji\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998c2dd0-5224-43ce-bc82-162b7f1a787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:77: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1370' max='1370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1370/1370 35:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.605356</td>\n",
       "      <td>0.725777</td>\n",
       "      <td>0.725107</td>\n",
       "      <td>0.732231</td>\n",
       "      <td>0.728370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.566617</td>\n",
       "      <td>0.714808</td>\n",
       "      <td>0.712687</td>\n",
       "      <td>0.728132</td>\n",
       "      <td>0.718660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.609758</td>\n",
       "      <td>0.691042</td>\n",
       "      <td>0.677523</td>\n",
       "      <td>0.747627</td>\n",
       "      <td>0.698997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.610600</td>\n",
       "      <td>0.607262</td>\n",
       "      <td>0.702011</td>\n",
       "      <td>0.694458</td>\n",
       "      <td>0.713887</td>\n",
       "      <td>0.697391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.610600</td>\n",
       "      <td>0.525154</td>\n",
       "      <td>0.749543</td>\n",
       "      <td>0.748976</td>\n",
       "      <td>0.749403</td>\n",
       "      <td>0.748795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.610600</td>\n",
       "      <td>0.669136</td>\n",
       "      <td>0.731261</td>\n",
       "      <td>0.727043</td>\n",
       "      <td>0.756803</td>\n",
       "      <td>0.736468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.610600</td>\n",
       "      <td>0.734300</td>\n",
       "      <td>0.736746</td>\n",
       "      <td>0.736004</td>\n",
       "      <td>0.736711</td>\n",
       "      <td>0.735792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.753715</td>\n",
       "      <td>0.720293</td>\n",
       "      <td>0.719558</td>\n",
       "      <td>0.726940</td>\n",
       "      <td>0.722943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>1.040629</td>\n",
       "      <td>0.738574</td>\n",
       "      <td>0.738150</td>\n",
       "      <td>0.738278</td>\n",
       "      <td>0.738068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>1.159184</td>\n",
       "      <td>0.733090</td>\n",
       "      <td>0.733067</td>\n",
       "      <td>0.733439</td>\n",
       "      <td>0.733657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       264\n",
      "           1       0.75      0.72      0.74       283\n",
      "\n",
      "    accuracy                           0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\2794703859.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load Dataset\n",
    "def load_data(csv_path):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    X = data['Processed_Text'].values  # Feature column\n",
    "    y = data['Class'].values           # Label column\n",
    "    \n",
    "    # Encode labels if they are strings\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)  # Convert string labels to integers\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# 2. Tokenizer Setup\n",
    "def tokenize_data(texts, tokenizer, max_len=128):\n",
    "    return tokenizer(list(texts), padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "\n",
    "# 3. Dataset Class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Ensure labels are integers\n",
    "        return item\n",
    "\n",
    "\n",
    "# 4. Metrics Calculation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    report = classification_report(labels, preds, output_dict=True)\n",
    "    return {\n",
    "        'accuracy': report['accuracy'],\n",
    "        'f1': report['macro avg']['f1-score'],\n",
    "        'precision': report['macro avg']['precision'],\n",
    "        'recall': report['macro avg']['recall'],\n",
    "    }\n",
    "\n",
    "# 5. Train and Evaluate Model\n",
    "def train_and_evaluate(csv_path, save_path):\n",
    "    texts, labels = load_data(csv_path)\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "    encodings = tokenize_data(texts, tokenizer)\n",
    "    dataset = CustomDataset(encodings, labels)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=len(set(labels)))\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    preds = trainer.predict(test_dataset)\n",
    "    print(\"Classification Report:\\n\", classification_report([item['labels'].item() for item in test_dataset], np.argmax(preds.predictions, axis=1)))\n",
    "\n",
    "csv_path = \"tokens_generated.csv\"  # Replace with your CSV file path\n",
    "save_path = \"./xlm-r-saved-model_tenepochs\"\n",
    "train_and_evaluate(csv_path, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4f460b-f997-41f9-8625-db0ff88afd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:81: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1370' max='1370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1370/1370 40:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690495</td>\n",
       "      <td>0.542962</td>\n",
       "      <td>0.463069</td>\n",
       "      <td>0.649039</td>\n",
       "      <td>0.553956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.584620</td>\n",
       "      <td>0.703839</td>\n",
       "      <td>0.700110</td>\n",
       "      <td>0.709160</td>\n",
       "      <td>0.701308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.615093</td>\n",
       "      <td>0.672761</td>\n",
       "      <td>0.641298</td>\n",
       "      <td>0.742353</td>\n",
       "      <td>0.665139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.552497</td>\n",
       "      <td>0.716636</td>\n",
       "      <td>0.714791</td>\n",
       "      <td>0.727277</td>\n",
       "      <td>0.719383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.559052</td>\n",
       "      <td>0.740402</td>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.760497</td>\n",
       "      <td>0.736394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.745759</td>\n",
       "      <td>0.758684</td>\n",
       "      <td>0.755843</td>\n",
       "      <td>0.765516</td>\n",
       "      <td>0.756295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.885713</td>\n",
       "      <td>0.755027</td>\n",
       "      <td>0.754133</td>\n",
       "      <td>0.762821</td>\n",
       "      <td>0.757251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>0.805122</td>\n",
       "      <td>0.753199</td>\n",
       "      <td>0.753037</td>\n",
       "      <td>0.753016</td>\n",
       "      <td>0.753064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>1.211972</td>\n",
       "      <td>0.762340</td>\n",
       "      <td>0.762110</td>\n",
       "      <td>0.765700</td>\n",
       "      <td>0.763767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>1.247332</td>\n",
       "      <td>0.751371</td>\n",
       "      <td>0.751071</td>\n",
       "      <td>0.751239</td>\n",
       "      <td>0.750983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       281\n",
      "           1       0.75      0.74      0.74       266\n",
      "\n",
      "    accuracy                           0.75       547\n",
      "   macro avg       0.75      0.75      0.75       547\n",
      "weighted avg       0.75      0.75      0.75       547\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN BALAJI\\AppData\\Local\\Temp\\ipykernel_12592\\3843466934.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder  # This was missing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. IndicBERT Tokenizer and Model Setup\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai4bharat/indic-bert\", num_labels=2)\n",
    "\n",
    "# 1. Load Dataset\n",
    "def load_data(csv_path):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    X = data['Processed_Text'].values  # Feature column\n",
    "    y = data['Class'].values           # Label column\n",
    "    \n",
    "    # Encode labels if they are strings\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)  # Convert string labels to integers\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# 2. Tokenizer Setup\n",
    "def tokenize_data(texts, tokenizer, max_len=128):\n",
    "    return tokenizer(list(texts), padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "\n",
    "# 3. Dataset Class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Ensure labels are integers\n",
    "        return item\n",
    "\n",
    "\n",
    "# 4. Metrics Calculation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    report = classification_report(labels, preds, output_dict=True)\n",
    "    return {\n",
    "        'accuracy': report['accuracy'],\n",
    "        'f1': report['macro avg']['f1-score'],\n",
    "        'precision': report['macro avg']['precision'],\n",
    "        'recall': report['macro avg']['recall'],\n",
    "    }\n",
    "\n",
    "# 5. Train and Evaluate Model\n",
    "def train_and_evaluate(csv_path, save_path):\n",
    "    texts, labels = load_data(csv_path)\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "    encodings = tokenize_data(texts, tokenizer)\n",
    "    dataset = CustomDataset(encodings, labels)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=len(set(labels)))\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    preds = trainer.predict(test_dataset)\n",
    "    print(\"Classification Report:\\n\", classification_report([item['labels'].item() for item in test_dataset], np.argmax(preds.predictions, axis=1)))\n",
    "\n",
    "csv_path = \"tokens_generated.csv\"  # Replace with your CSV file path\n",
    "save_path = \"./IndicBERTs_model\"\n",
    "train_and_evaluate(csv_path, save_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ebf9a8-a11d-44cb-9f58-cb89e88284a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "Device Name: No GPU detected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0445a244-a87a-4c9e-873c-0e6f7c1afe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load saved XLM-R model and tokenizer\n",
    "model_path = \"./xlm-r-saved-model\"  # Replace with your saved model path\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Load test data\n",
    "test_data_path = \"filtered_file.csv\"  # Replace with your test data path\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "texts = test_data['Text'].values  # Replace with your text column name\n",
    "true_labels = test_data['Class'].values     # Replace with your label column name\n",
    "\n",
    "# Tokenize the test data\n",
    "encodings = tokenizer(list(texts), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Perform prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encodings)\n",
    "predictions = torch.argmax(outputs.logits, axis=1).numpy()\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(true_labels, predictions))\n",
    "\n",
    "# Compute and display confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.config.id2label.values())\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b5751d-32a4-4f7c-970b-ca5a8cd08710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6277b-a94f-4b92-958e-2ba5609dfcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e164b4-2e0c-4edf-a500-89c032f22092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1b97f-8bb4-4c27-8079-847094cf60eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
